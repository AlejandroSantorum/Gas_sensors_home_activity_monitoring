{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from preprocessing import *\n",
    "from plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = group_datafiles_byID('../datasets/raw/HT_Sensor_metadata.dat', '../datasets/raw/HT_Sensor_dataset.dat')\n",
    "df_db = reclassify_series_samples(df_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing sklearn DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = split_series_byID(100, 0.75, df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(701805, 11)\n",
      "(701805,)\n",
      "(227186, 11)\n",
      "(227186,)\n"
     ]
    }
   ],
   "source": [
    "features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = DecisionTreeClassifier(\n",
    "                criterion='entropy',\n",
    "                splitter='best',\n",
    "                max_features='sqrt',\n",
    "                random_state=0)\n",
    "            # Default input args:\n",
    "            #    max_depth=None -> If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples\n",
    "            #    min_samples_split=2\n",
    "            #    min_samples_leaf=1\n",
    "            #    ccp_alpha=0.0 -> By default, no pruning is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (mins): 0.07512848774592082\n"
     ]
    }
   ],
   "source": [
    "start_t = time.time()\n",
    "\n",
    "clf_tree.fit(xtrain, ytrain)\n",
    "\n",
    "end_t = time.time()\n",
    "print('Training time (mins):', (end_t-start_t)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7461287227205902"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "print(clf_tree.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing RandomForest (ensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = group_datafiles_byID('../datasets/raw/HT_Sensor_metadata.dat', '../datasets/raw/HT_Sensor_dataset.dat')\n",
    "df_db = reclassify_series_samples(df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list = [2, 4, 6, 8, 10, 14, 18, 22, 26, 32, 36, 40]\n",
    "n_estimators_list = [400, 500, 700, 1000]\n",
    "criterions = ['entropy', 'gini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 2\n",
      "Criterion: gini\n",
      "Training time (mins): 6.274376936753591\n",
      "Precision (score): 0.82572384867891\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 5.355758766333262\n",
      "Precision (score): 0.8250252487058514\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 4.3957205533981325\n",
      "Precision (score): 0.8006146586511463\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 6.587088612715403\n",
      "Precision (score): 0.830885825237377\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 5.570846013228098\n",
      "Precision (score): 0.8388239826545058\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 9.296311287085215\n",
      "Precision (score): 0.7938500736418873\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 8.30868130127589\n",
      "Precision (score): 0.8073012898149703\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 13.147202316919962\n",
      "Precision (score): 0.8519079655674694\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 11.171217199166616\n",
      "Precision (score): 0.8534675867291059\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 7.344436502456665\n",
      "Precision (score): 0.8557942472694756\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 6.523063131173452\n",
      "Precision (score): 0.8236653467898551\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 9.697747317949931\n",
      "Precision (score): 0.8610006860450911\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 7.81781564950943\n",
      "Precision (score): 0.8545452844836455\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 13.41621394554774\n",
      "Precision (score): 0.8372852233676976\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 11.089528699715933\n",
      "Precision (score): 0.8188188095227039\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 19.107880850632984\n",
      "Precision (score): 0.8597149888972988\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 18.51077799399694\n",
      "Precision (score): 0.8325345596586974\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 8\n",
      "Criterion: entropy\n",
      "Training time (mins): 11.296044099330903\n",
      "Precision (score): 0.9009183583363586\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 8\n",
      "Criterion: gini\n",
      "Training time (mins): 9.272575398286184\n",
      "Precision (score): 0.8544559272707615\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 8\n",
      "Criterion: entropy\n",
      "Training time (mins): 13.878429333368937\n",
      "Precision (score): 0.8253371645514492\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 8\n",
      "Criterion: gini\n",
      "Training time (mins): 11.560842712720236\n",
      "Precision (score): 0.8026438825837443\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 8\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.382872068881987\n",
      "Precision (score): 0.8310640791423942\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 8\n",
      "Criterion: gini\n",
      "Training time (mins): 14.455410599708557\n",
      "Precision (score): 0.7959992140987037\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 8\n",
      "Criterion: entropy\n",
      "Training time (mins): 26.813397045930227\n",
      "Precision (score): 0.8576871035535041\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 8\n",
      "Criterion: gini\n",
      "Training time (mins): 24.597335477670033\n",
      "Precision (score): 0.8277659386749555\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 11.933628833293914\n",
      "Precision (score): 0.8019496883151332\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 10.155005248387655\n",
      "Precision (score): 0.8303129393768691\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 14.831617462635041\n",
      "Precision (score): 0.803713777030231\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 13.500326363245646\n",
      "Precision (score): 0.8093935466592699\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 22.15176858504613\n",
      "Precision (score): 0.8103893294526575\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 20.351263614495597\n",
      "Precision (score): 0.8366451660024742\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 31.385870317618053\n",
      "Precision (score): 0.7893321160538548\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 28.612787818908693\n",
      "Precision (score): 0.8438155293646623\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 14\n",
      "Criterion: entropy\n",
      "Training time (mins): 14.68951538403829\n",
      "Precision (score): 0.8384719142223543\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 14\n",
      "Criterion: gini\n",
      "Training time (mins): 14.105405366420745\n",
      "Precision (score): 0.8622737636164044\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 14\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.87949724992116\n",
      "Precision (score): 0.7571748478478891\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 14\n",
      "Criterion: gini\n",
      "Training time (mins): 17.604650568962096\n",
      "Precision (score): 0.7957882109268466\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 14\n",
      "Criterion: entropy\n",
      "Training time (mins): 26.34679125150045\n",
      "Precision (score): 0.7941923369249341\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 14\n",
      "Criterion: gini\n",
      "Training time (mins): 23.933551267782846\n",
      "Precision (score): 0.815925519364874\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 14\n",
      "Criterion: entropy\n",
      "Training time (mins): 37.51170394817988\n",
      "Precision (score): 0.8438593962836063\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 14\n",
      "Criterion: gini\n",
      "Training time (mins): 35.224063181877135\n",
      "Precision (score): 0.7815720644652476\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 18\n",
      "Criterion: entropy\n",
      "Training time (mins): 16.2227992494901\n",
      "Precision (score): 0.8211332662581177\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 18\n",
      "Criterion: gini\n",
      "Training time (mins): 14.905044051011403\n",
      "Precision (score): 0.8020904863514653\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 18\n",
      "Criterion: entropy\n",
      "Training time (mins): 19.608232017358144\n",
      "Precision (score): 0.7938552882689726\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 18\n",
      "Criterion: gini\n",
      "Training time (mins): 19.428412850697836\n",
      "Precision (score): 0.8252713549895567\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 18\n",
      "Criterion: entropy\n",
      "Training time (mins): 28.236671368281048\n",
      "Precision (score): 0.8413774211373973\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 18\n",
      "Criterion: gini\n",
      "Training time (mins): 26.612028364340464\n",
      "Precision (score): 0.8387357169698404\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 18\n",
      "Criterion: entropy\n",
      "Training time (mins): 39.657892020543414\n",
      "Precision (score): 0.7322617602130743\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 18\n",
      "Criterion: gini\n",
      "Training time (mins): 38.3241659005483\n",
      "Precision (score): 0.8328183781444115\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 22\n",
      "Criterion: entropy\n",
      "Training time (mins): 16.181909596920015\n",
      "Precision (score): 0.8439518462240496\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 22\n",
      "Criterion: gini\n",
      "Training time (mins): 16.157032334804533\n",
      "Precision (score): 0.8797954092567775\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 22\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.401815148194633\n",
      "Precision (score): 0.8156491785668311\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 22\n",
      "Criterion: gini\n",
      "Training time (mins): 20.928504212697348\n",
      "Precision (score): 0.8369281669529809\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 22\n",
      "Criterion: entropy\n",
      "Training time (mins): 31.08846568663915\n",
      "Precision (score): 0.7851257966809084\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 22\n",
      "Criterion: gini\n",
      "Training time (mins): 24.543841485182444\n",
      "Precision (score): 0.8218483112581275\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 22\n",
      "Criterion: entropy\n",
      "Training time (mins): 38.951690185070035\n",
      "Precision (score): 0.8023711179519152\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 22\n",
      "Criterion: gini\n",
      "Training time (mins): 40.32212035258611\n",
      "Precision (score): 0.7601177560258646\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 26\n",
      "Criterion: entropy\n",
      "Training time (mins): 15.988759617010752\n",
      "Precision (score): 0.8096645590063761\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 26\n",
      "Criterion: gini\n",
      "Training time (mins): 15.208831663926443\n",
      "Precision (score): 0.8662324071897143\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 26\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.171444602807362\n",
      "Precision (score): 0.8533343209145001\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 26\n",
      "Criterion: gini\n",
      "Training time (mins): 19.03989771207174\n",
      "Precision (score): 0.7946293376451092\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 26\n",
      "Criterion: entropy\n",
      "Training time (mins): 26.445433151721954\n",
      "Precision (score): 0.8417184722685891\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 26\n",
      "Criterion: gini\n",
      "Training time (mins): 29.066462667783103\n",
      "Precision (score): 0.8228491865085644\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 26\n",
      "Criterion: entropy\n",
      "Training time (mins): 41.083224415779114\n",
      "Precision (score): 0.8904761904761904\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 26\n",
      "Criterion: gini\n",
      "Training time (mins): 40.75688408613205\n",
      "Precision (score): 0.8409333164288297\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 32\n",
      "Criterion: entropy\n",
      "Training time (mins): 16.214678899447122\n",
      "Precision (score): 0.8121319225273429\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 32\n",
      "Criterion: gini\n",
      "Training time (mins): 17.175767612457275\n",
      "Precision (score): 0.7949288296126215\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 32\n",
      "Criterion: entropy\n",
      "Training time (mins): 20.979872715473174\n",
      "Precision (score): 0.8059125093159285\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 32\n",
      "Criterion: gini\n",
      "Training time (mins): 22.866595486799877\n",
      "Precision (score): 0.8549631987268749\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 32\n",
      "Criterion: entropy\n",
      "Training time (mins): 27.211875915527344\n",
      "Precision (score): 0.8477799703996053\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 32\n",
      "Criterion: gini\n",
      "Training time (mins): 25.160607437292736\n",
      "Precision (score): 0.8224215605256844\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 32\n",
      "Criterion: entropy\n",
      "Training time (mins): 42.96150778532028\n",
      "Precision (score): 0.887671117829848\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 32\n",
      "Criterion: gini\n",
      "Training time (mins): 49.587155656019846\n",
      "Precision (score): 0.8481588570456672\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 36\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.756543719768523\n",
      "Precision (score): 0.8588261092025437\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 36\n",
      "Criterion: gini\n",
      "Training time (mins): 15.886099580923716\n",
      "Precision (score): 0.8491512228659246\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 36\n",
      "Criterion: entropy\n",
      "Training time (mins): 19.701321947574616\n",
      "Precision (score): 0.8848147709788141\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 36\n",
      "Criterion: gini\n",
      "Training time (mins): 19.23148227930069\n",
      "Precision (score): 0.8137442261052884\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 36\n",
      "Criterion: entropy\n",
      "Training time (mins): 25.298999126752218\n",
      "Precision (score): 0.8452238798575017\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 36\n",
      "Criterion: gini\n",
      "Training time (mins): 28.251189935207368\n",
      "Precision (score): 0.8022400808788082\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 36\n",
      "Criterion: entropy\n",
      "Training time (mins): 47.44691472848256\n",
      "Precision (score): 0.8414715519216022\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 36\n",
      "Criterion: gini\n",
      "Training time (mins): 41.04220586617787\n",
      "Precision (score): 0.7968791117471896\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 40\n",
      "Criterion: entropy\n",
      "Training time (mins): 16.507924381891886\n",
      "Precision (score): 0.7995290514576291\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 40\n",
      "Criterion: gini\n",
      "Training time (mins): 16.79126339753469\n",
      "Precision (score): 0.7958682468097512\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 40\n",
      "Criterion: entropy\n",
      "Training time (mins): 20.838901182015736\n",
      "Precision (score): 0.8231577662247815\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 40\n",
      "Criterion: gini\n",
      "Training time (mins): 17.55820163488388\n",
      "Precision (score): 0.8514073003116902\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 40\n",
      "Criterion: entropy\n",
      "Training time (mins): 28.988572335243227\n",
      "Precision (score): 0.7782293431789898\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 40\n",
      "Criterion: gini\n",
      "Training time (mins): 31.353501796722412\n",
      "Precision (score): 0.8433087364489387\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 40\n",
      "Criterion: entropy\n",
      "Training time (mins): 43.28982339700063\n",
      "Precision (score): 0.7859979341214277\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 40\n",
      "Criterion: gini\n",
      "Training time (mins): 44.331841011842094\n",
      "Precision (score): 0.8497177017602126\n",
      "==========================================\n",
      "==================================================\n",
      "OVERALL TIME (hours): 32.631774254772395\n",
      "==================================================\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "main_start = time.time()\n",
    "\n",
    "for d in max_depth_list:\n",
    "    for nest in n_estimators_list:\n",
    "        for crit in criterions:\n",
    "\n",
    "            df_train, df_test = split_series_byID(100, 0.77, df_db)\n",
    "            features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "            xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "            xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "            \n",
    "            clf_randFor = RandomForestClassifier(\n",
    "                        n_estimators=nest,\n",
    "                        criterion=crit,\n",
    "                        max_depth=d,\n",
    "                        max_features='sqrt',\n",
    "                        random_state=0)\n",
    "\n",
    "            start_t = time.time()\n",
    "\n",
    "            clf_randFor.fit(xtrain, ytrain)\n",
    "\n",
    "            end_t = time.time()\n",
    "            print('==========================================')\n",
    "            print('Number of estimators:',nest)\n",
    "            print('Max depth:', d)\n",
    "            print('Criterion:', crit)\n",
    "            print('Training time (mins):', (end_t-start_t)/60)\n",
    "            print('Precision (score):', clf_randFor.score(xtest, ytest))\n",
    "            print('==========================================')\n",
    "\n",
    "main_end = time.time()\n",
    "\n",
    "print('==================================================')\n",
    "print('OVERALL TIME (hours):', (main_end-main_start)/(60*60))\n",
    "print('==================================================')\n",
    "print('==================================================')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Number of estimators: 5000\n",
      "Max depth: 7\n",
      "Criterion: entropy\n",
      "Training time (mins): 132.90388695001602\n",
      "Precision (score): 0.8471366322797279\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = split_series_byID(100, 0.77, df_db)\n",
    "features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "\n",
    "clf_randFor = RandomForestClassifier(\n",
    "            n_estimators=5000,\n",
    "            criterion='entropy',\n",
    "            max_depth=7,\n",
    "            max_features='sqrt',\n",
    "            random_state=0)\n",
    "\n",
    "start_t = time.time()\n",
    "\n",
    "clf_randFor.fit(xtrain, ytrain)\n",
    "\n",
    "end_t = time.time()\n",
    "print('==========================================')\n",
    "print('Number of estimators:',5000)\n",
    "print('Max depth:', 7)\n",
    "print('Criterion:', 'entropy')\n",
    "print('Training time (mins):', (end_t-start_t)/60)\n",
    "print('Precision (score):', clf_randFor.score(xtest, ytest))\n",
    "print('==========================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting excess background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = group_datafiles_byID('../datasets/raw/HT_Sensor_metadata.dat', '../datasets/raw/HT_Sensor_dataset.dat')\n",
    "df_db = reclassify_series_samples(df_db)\n",
    "df_db = remove_excess_bg(df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list = [2, 4, 6, 10, 20, 30, 50, 70, 80, 100]\n",
    "n_estimators_list = [100, 200, 300, 400]\n",
    "criterions = ['entropy', 'gini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g estimate: 0.7714623631607841\n",
      "Precision on test set (score): 0.7386642435256702\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 1.3233341852823892\n",
      "Out-of-bag estimate: 0.7977355781143606\n",
      "Precision on test set (score): 0.7995242742132227\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 0.9155715505282084\n",
      "Out-of-bag estimate: 0.8013998709052768\n",
      "Precision on test set (score): 0.7543262756057798\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 2.856734116872152\n",
      "Out-of-bag estimate: 0.8114948888605821\n",
      "Precision on test set (score): 0.638909702991801\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 3.2667909224828082\n",
      "Out-of-bag estimate: 0.8011770606397818\n",
      "Precision on test set (score): 0.8161678142057008\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 3.670349482695262\n",
      "Out-of-bag estimate: 0.8125563563993758\n",
      "Precision on test set (score): 0.6986538262400331\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 2.957198635737101\n",
      "Out-of-bag estimate: 0.80725441699595\n",
      "Precision on test set (score): 0.7889026658400496\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 4.364201064904531\n",
      "Out-of-bag estimate: 0.8021673313018685\n",
      "Precision on test set (score): 0.7947798413527764\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 3.4882604161898296\n",
      "Out-of-bag estimate: 0.8047962206741933\n",
      "Precision on test set (score): 0.7437155765241109\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 1.6060381015141805\n",
      "Out-of-bag estimate: 0.8376179558153256\n",
      "Precision on test set (score): 0.7980325303225085\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 1.4334094166755675\n",
      "Out-of-bag estimate: 0.8577341397596348\n",
      "Precision on test set (score): 0.8265834731543624\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 3.1812836011250814\n",
      "Out-of-bag estimate: 0.8508741079120201\n",
      "Precision on test set (score): 0.8168459632809584\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 2.528444751103719\n",
      "Out-of-bag estimate: 0.8643776977987159\n",
      "Precision on test set (score): 0.7139529114852403\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 5.006190383434296\n",
      "Out-of-bag estimate: 0.8621610611555467\n",
      "Precision on test set (score): 0.8040901721947159\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 4.032466582457224\n",
      "Out-of-bag estimate: 0.8576398475895963\n",
      "Precision on test set (score): 0.7723203567141143\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 8.157015152772267\n",
      "Out-of-bag estimate: 0.8653364119420441\n",
      "Precision on test set (score): 0.7482914562673643\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 4.918913050492605\n",
      "Out-of-bag estimate: 0.8581978098271192\n",
      "Precision on test set (score): 0.7576617422827195\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 2.117291967074076\n",
      "Out-of-bag estimate: 0.9707360348785863\n",
      "Precision on test set (score): 0.7207299176928476\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 1.8580543677012125\n",
      "Out-of-bag estimate: 0.954850337921323\n",
      "Precision on test set (score): 0.7471967861995629\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 4.294099032878876\n",
      "Out-of-bag estimate: 0.9660817064769169\n",
      "Precision on test set (score): 0.7060967017482056\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 3.606910260518392\n",
      "Out-of-bag estimate: 0.9626010781671159\n",
      "Precision on test set (score): 0.7199733507704835\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 6.5376540144284565\n",
      "Out-of-bag estimate: 0.960596517813452\n",
      "Precision on test set (score): 0.7779475310401441\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 5.543705888589224\n",
      "Out-of-bag estimate: 0.9596358455520495\n",
      "Precision on test set (score): 0.7636238610967853\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 8.461165217558543\n",
      "Out-of-bag estimate: 0.9620280457733366\n",
      "Precision on test set (score): 0.8074593069436047\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 6.703801234563191\n",
      "Out-of-bag estimate: 0.9590291918517148\n",
      "Precision on test set (score): 0.7264300874611654\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 20\n",
      "Criterion: entropy\n",
      "Training time (mins): 2.7833861827850344\n",
      "Out-of-bag estimate: 0.9995434597205196\n",
      "Precision on test set (score): 0.7305580625752106\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 20\n",
      "Criterion: gini\n",
      "Training time (mins): 2.493499199549357\n",
      "Out-of-bag estimate: 0.9995471330035532\n",
      "Precision on test set (score): 0.79271035484327\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 20\n",
      "Criterion: entropy\n",
      "Training time (mins): 5.992452728748321\n",
      "Out-of-bag estimate: 0.9995740947550849\n",
      "Precision on test set (score): 0.8228997576869692\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 20\n",
      "Criterion: gini\n",
      "Training time (mins): 4.771654136975607\n",
      "Out-of-bag estimate: 0.9995051777484991\n",
      "Precision on test set (score): 0.7053205703896787\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 20\n",
      "Criterion: entropy\n",
      "Training time (mins): 7.7073642690976465\n",
      "Out-of-bag estimate: 0.9995886589683327\n",
      "Precision on test set (score): 0.6971488326433053\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 20\n",
      "Criterion: gini\n",
      "Training time (mins): 7.365615483125051\n",
      "Out-of-bag estimate: 0.9993713335978971\n",
      "Precision on test set (score): 0.7533419880004211\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 20\n",
      "Criterion: entropy\n",
      "Training time (mins): 10.631541550159454\n",
      "Out-of-bag estimate: 0.999590333452737\n",
      "Precision on test set (score): 0.7456179674541624\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 20\n",
      "Criterion: gini\n",
      "Training time (mins): 9.584510481357574\n",
      "Out-of-bag estimate: 0.9994763749155604\n",
      "Precision on test set (score): 0.7230429380091122\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 30\n",
      "Criterion: entropy\n",
      "Training time (mins): 2.701177934805552\n",
      "Out-of-bag estimate: 0.99961773403603\n",
      "Precision on test set (score): 0.7911556290972477\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 30\n",
      "Criterion: gini\n",
      "Training time (mins): 2.4888013005256653\n",
      "Out-of-bag estimate: 0.9995696634335749\n",
      "Precision on test set (score): 0.777370259189609\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 30\n",
      "Criterion: entropy\n",
      "Training time (mins): 5.192964398860932\n",
      "Out-of-bag estimate: 0.9996016994158258\n",
      "Precision on test set (score): 0.8127468761474526\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 30\n",
      "Criterion: gini\n",
      "Training time (mins): 4.9408507188161215\n",
      "Out-of-bag estimate: 0.9995701294691881\n",
      "Precision on test set (score): 0.7211216534719285\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 30\n",
      "Criterion: entropy\n",
      "Training time (mins): 7.722656079133352\n",
      "Out-of-bag estimate: 0.9996328507755534\n",
      "Precision on test set (score): 0.6851929792631184\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 30\n",
      "Criterion: gini\n",
      "Training time (mins): 7.15147705078125\n",
      "Out-of-bag estimate: 0.9996060601753235\n",
      "Precision on test set (score): 0.7339205926158188\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 30\n",
      "Criterion: entropy\n",
      "Training time (mins): 10.481718818346659\n",
      "Out-of-bag estimate: 0.999622282587423\n",
      "Precision on test set (score): 0.6889519227316793\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 30\n",
      "Criterion: gini\n",
      "Training time (mins): 9.473810851573944\n",
      "Out-of-bag estimate: 0.999594421923267\n",
      "Precision on test set (score): 0.7700577367205542\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 50\n",
      "Criterion: entropy\n",
      "Training time (mins): 2.8685227831204734\n",
      "Out-of-bag estimate: 0.9996056238045472\n",
      "Precision on test set (score): 0.7743028139196906\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 50\n",
      "Criterion: gini\n",
      "Training time (mins): 2.694016782442729\n",
      "Out-of-bag estimate: 0.9995740111463811\n",
      "Precision on test set (score): 0.8119698287003313\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 50\n",
      "Criterion: entropy\n",
      "Training time (mins): 5.6547313809394835\n",
      "Out-of-bag estimate: 0.999637294134528\n",
      "Precision on test set (score): 0.824204975575038\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 50\n",
      "Criterion: gini\n",
      "Training time (mins): 5.177982215086619\n",
      "Out-of-bag estimate: 0.999570373774816\n",
      "Precision on test set (score): 0.7675857230926213\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 50\n",
      "Criterion: entropy\n",
      "Training time (mins): 8.329341936111451\n",
      "Out-of-bag estimate: 0.9996124669385857\n",
      "Precision on test set (score): 0.7322266421868625\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 50\n",
      "Criterion: gini\n",
      "Training time (mins): 7.409495230515798\n",
      "Out-of-bag estimate: 0.9996013789918835\n",
      "Precision on test set (score): 0.6729862139683263\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 50\n",
      "Criterion: entropy\n",
      "Training time (mins): 10.101464120546977\n",
      "Out-of-bag estimate: 0.9996140607276425\n",
      "Precision on test set (score): 0.8232390513119395\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 50\n",
      "Criterion: gini\n",
      "Training time (mins): 9.597664332389831\n",
      "Out-of-bag estimate: 0.9995862427690998\n",
      "Precision on test set (score): 0.8314649373943638\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 70\n",
      "Criterion: entropy\n",
      "Training time (mins): 2.5774551669756574\n",
      "Out-of-bag estimate: 0.9995564251031708\n",
      "Precision on test set (score): 0.6799026013917279\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 70\n",
      "Criterion: gini\n",
      "Training time (mins): 2.349472979704539\n",
      "Out-of-bag estimate: 0.9995732907814932\n",
      "Precision on test set (score): 0.7399874256846936\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 70\n",
      "Criterion: entropy\n",
      "Training time (mins): 4.994911269346873\n",
      "Out-of-bag estimate: 0.9996050465380113\n",
      "Precision on test set (score): 0.8082763393584107\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 70\n",
      "Criterion: gini\n",
      "Training time (mins): 4.848562971750895\n",
      "Out-of-bag estimate: 0.9996076215588411\n",
      "Precision on test set (score): 0.7891044160132068\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 70\n",
      "Criterion: entropy\n",
      "Training time (mins): 8.64193274974823\n",
      "Out-of-bag estimate: 0.9996210115982482\n",
      "Precision on test set (score): 0.7026330345122677\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 70\n",
      "Criterion: gini\n",
      "Training time (mins): 8.237271197636922\n",
      "Out-of-bag estimate: 0.9996172817680417\n",
      "Precision on test set (score): 0.6886986387224548\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 70\n",
      "Criterion: entropy\n",
      "Training time (mins): 10.434654215971628\n",
      "Out-of-bag estimate: 0.9996043406044952\n",
      "Precision on test set (score): 0.7396236570269319\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 70\n",
      "Criterion: gini\n",
      "Training time (mins): 9.331579148769379\n",
      "Out-of-bag estimate: 0.9996106752837204\n",
      "Precision on test set (score): 0.7093692378135558\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 80\n",
      "Criterion: entropy\n",
      "Training time (mins): 2.6620495557785033\n",
      "Out-of-bag estimate: 0.9996042089776598\n",
      "Precision on test set (score): 0.695956627375256\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 80\n",
      "Criterion: gini\n",
      "Training time (mins): 2.7640210151672364\n",
      "Out-of-bag estimate: 0.9995892426078845\n",
      "Precision on test set (score): 0.7232523826614029\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 80\n",
      "Criterion: entropy\n",
      "Training time (mins): 5.550745451450348\n",
      "Out-of-bag estimate: 0.9996024159080411\n",
      "Precision on test set (score): 0.7611339015942421\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 80\n",
      "Criterion: gini\n",
      "Training time (mins): 5.36564751068751\n",
      "Out-of-bag estimate: 0.9995866820655613\n",
      "Precision on test set (score): 0.7641610300158689\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 80\n",
      "Criterion: entropy\n",
      "Training time (mins): 8.74057751496633\n",
      "Out-of-bag estimate: 0.9996241752735169\n",
      "Precision on test set (score): 0.5987579537888958\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 80\n",
      "Criterion: gini\n",
      "Training time (mins): 8.147638400395712\n",
      "Out-of-bag estimate: 0.9995879654207903\n",
      "Precision on test set (score): 0.7348085391003846\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 80\n",
      "Criterion: entropy\n",
      "Training time (mins): 10.88300295273463\n",
      "Out-of-bag estimate: 0.9995899942518802\n",
      "Precision on test set (score): 0.7017006487010509\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 80\n",
      "Criterion: gini\n",
      "Training time (mins): 10.246306482950846\n",
      "Out-of-bag estimate: 0.9995814871022858\n",
      "Precision on test set (score): 0.6423683747482845\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 100\n",
      "Criterion: entropy\n",
      "Training time (mins): 2.6295805017153424\n",
      "Out-of-bag estimate: 0.9995931237920862\n",
      "Precision on test set (score): 0.8050163202198934\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 100\n",
      "Max depth: 100\n",
      "Criterion: gini\n",
      "Training time (mins): 2.5014835000038147\n",
      "Out-of-bag estimate: 0.9995728437876078\n",
      "Precision on test set (score): 0.8134043801329683\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 100\n",
      "Criterion: entropy\n",
      "Training time (mins): 5.34396098057429\n",
      "Out-of-bag estimate: 0.999596714915191\n",
      "Precision on test set (score): 0.7050388915096927\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 200\n",
      "Max depth: 100\n",
      "Criterion: gini\n",
      "Training time (mins): 5.092622232437134\n",
      "Out-of-bag estimate: 0.9995718679775004\n",
      "Precision on test set (score): 0.7779818397517795\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 100\n",
      "Criterion: entropy\n",
      "Training time (mins): 8.567968046665191\n",
      "Out-of-bag estimate: 0.999610151185757\n",
      "Precision on test set (score): 0.7664399834346869\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 300\n",
      "Max depth: 100\n",
      "Criterion: gini\n",
      "Training time (mins): 8.094989116986593\n",
      "Out-of-bag estimate: 0.9995779165963194\n",
      "Precision on test set (score): 0.8658546612010947\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 100\n",
      "Criterion: entropy\n",
      "Training time (mins): 11.360808102289836\n",
      "Out-of-bag estimate: 0.9996159414461514\n",
      "Precision on test set (score): 0.7128615080712367\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 100\n",
      "Criterion: gini\n",
      "Training time (mins): 10.69666318098704\n",
      "Out-of-bag estimate: 0.99958524257356\n",
      "Precision on test set (score): 0.877748101712873\n",
      "==========================================\n",
      "==================================================\n",
      "OVERALL TIME (hours): 7.072681693964534\n",
      "==================================================\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "main_start = time.time()\n",
    "\n",
    "for d in max_depth_list:\n",
    "    for nest in n_estimators_list:\n",
    "        for crit in criterions:\n",
    "\n",
    "            df_train, df_test = split_series_byID(100, 0.85, df_db)\n",
    "            features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "            xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "            xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "            \n",
    "            clf_randFor = RandomForestClassifier(\n",
    "                        n_estimators=nest,\n",
    "                        criterion=crit,\n",
    "                        max_depth=d,\n",
    "                        max_features='sqrt',\n",
    "                        oob_score=True,\n",
    "                        random_state=0)\n",
    "\n",
    "            start_t = time.time()\n",
    "\n",
    "            clf_randFor.fit(xtrain, ytrain)\n",
    "            oob_error = clf_randFor.oob_score_\n",
    "\n",
    "            end_t = time.time()\n",
    "            print('==========================================')\n",
    "            print('Number of estimators:',nest)\n",
    "            print('Max depth:', d)\n",
    "            print('Criterion:', crit)\n",
    "            print('Training time (mins):', (end_t-start_t)/60)\n",
    "            print('Out-of-bag estimate:', oob_error)\n",
    "            print('Precision on test set (score):', clf_randFor.score(xtest, ytest))\n",
    "            print('==========================================')\n",
    "\n",
    "main_end = time.time()\n",
    "\n",
    "print('==================================================')\n",
    "print('OVERALL TIME (hours):', (main_end-main_start)/(60*60))\n",
    "print('==================================================')\n",
    "print('==================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = group_datafiles_byID('../datasets/raw/HT_Sensor_metadata.dat', '../datasets/raw/HT_Sensor_dataset.dat')\n",
    "df_db = reclassify_series_samples(df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = ['deviance', 'exponential']\n",
    "estimators = [500, 1000]\n",
    "learning_rates = [0.1, 0.01]\n",
    "depths = [5, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Loss function: deviance\n",
      "Number of estimators: 500\n",
      "Learning rate: 0.1\n",
      "Max depth: 5\n",
      "Training time (mins): 111.22014693419139\n",
      "Precision (score): 0.7613230575135076\n",
      "==========================================\n",
      "==========================================\n",
      "Loss function: deviance\n",
      "Number of estimators: 500\n",
      "Learning rate: 0.1\n",
      "Max depth: 7\n",
      "Training time (mins): 152.49901788234712\n",
      "Precision (score): 0.7380312111885091\n",
      "==========================================\n",
      "==========================================\n",
      "Loss function: deviance\n",
      "Number of estimators: 500\n",
      "Learning rate: 0.01\n",
      "Max depth: 5\n",
      "Training time (mins): 117.28765278259912\n",
      "Precision (score): 0.8705405887202798\n",
      "==========================================\n",
      "==========================================\n",
      "Loss function: deviance\n",
      "Number of estimators: 500\n",
      "Learning rate: 0.01\n",
      "Max depth: 7\n",
      "Training time (mins): 157.71072766780853\n",
      "Precision (score): 0.9183072450085292\n",
      "==========================================\n",
      "==========================================\n",
      "Loss function: deviance\n",
      "Number of estimators: 1000\n",
      "Learning rate: 0.1\n",
      "Max depth: 5\n",
      "Training time (mins): 233.82789334456126\n",
      "Precision (score): 0.8355979223553905\n",
      "==========================================\n",
      "==========================================\n",
      "Loss function: deviance\n",
      "Number of estimators: 1000\n",
      "Learning rate: 0.1\n",
      "Max depth: 7\n",
      "Training time (mins): 305.2583548863729\n",
      "Precision (score): 0.8155505567883596\n",
      "==========================================\n",
      "==========================================\n",
      "Loss function: deviance\n",
      "Number of estimators: 1000\n",
      "Learning rate: 0.01\n",
      "Max depth: 5\n",
      "Training time (mins): 239.22515091896057\n",
      "Precision (score): 0.8343136775672255\n",
      "==========================================\n",
      "==========================================\n",
      "Loss function: deviance\n",
      "Number of estimators: 1000\n",
      "Learning rate: 0.01\n",
      "Max depth: 7\n",
      "Training time (mins): 309.5631645679474\n",
      "Precision (score): 0.8153522781985638\n",
      "==========================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ExponentialLoss requires 2 classes; got 3 class(es)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-69fa084997d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mstart_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mclf_boost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mend_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_check_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubsample\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb_losses.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_classes)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             raise ValueError(\"{0:s} requires 2 classes; got {1:d} class(es)\"\n\u001b[0;32m--> 791\u001b[0;31m                              .format(self.__class__.__name__, n_classes))\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;31m# we only need to fit one tree for binary clf.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ExponentialLoss requires 2 classes; got 3 class(es)"
     ]
    }
   ],
   "source": [
    "main_start = time.time()\n",
    "\n",
    "for l in losses:\n",
    "    for estim in estimators:\n",
    "        for lr in learning_rates:\n",
    "            for d in depths:\n",
    "                \n",
    "                df_train, df_test = split_series_byID(100, 0.8, df_db)\n",
    "                features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "                xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "                xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "\n",
    "                clf_boost = GradientBoostingClassifier(\n",
    "                                loss=l,\n",
    "                                learning_rate=lr,\n",
    "                                n_estimators=estim,\n",
    "                                max_depth=d,\n",
    "                                random_state=0)\n",
    "\n",
    "                start_t = time.time()\n",
    "\n",
    "                clf_boost.fit(xtrain, ytrain)\n",
    "\n",
    "                end_t = time.time()\n",
    "                print('==========================================')\n",
    "                print('Loss function:', l)\n",
    "                print('Number of estimators:', estim)\n",
    "                print('Learning rate:', lr)\n",
    "                print('Max depth:', d)\n",
    "                print('Training time (mins):', (end_t-start_t)/60)\n",
    "                print('Precision (score):', clf_boost.score(xtest, ytest))\n",
    "                print('==========================================')\n",
    "                \n",
    "main_end = time.time()\n",
    "print('==============================================================')\n",
    "print('Total time (hours):', (main_end-main_start)/(60*60))\n",
    "print('==============================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting with AdaBoost classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we are gonna store classifiers to study them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estim = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [500, 1000]\n",
    "learning_rates = [0.1, 0.01, 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Number of estimators: 500\n",
      "Learning rate: 0.1\n",
      "Training time (mins): 43.583362050851186\n",
      "Precision (score): 0.8719164179104477\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Learning rate: 0.01\n",
      "Training time (mins): 40.7228889465332\n",
      "Precision (score): 0.7880553532410779\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Learning rate: 0.001\n",
      "Training time (mins): 42.52133306662242\n",
      "Precision (score): 0.8655926945044344\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Learning rate: 0.1\n",
      "Training time (mins): 83.51484416325887\n",
      "Precision (score): 0.7885299402295479\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Learning rate: 0.01\n",
      "Training time (mins): 83.1132468978564\n",
      "Precision (score): 0.8277351931081416\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Learning rate: 0.001\n",
      "Training time (mins): 83.40477879842122\n",
      "Precision (score): 0.8240472648355809\n",
      "==========================================\n",
      "==============================================================\n",
      "Total time (hours): 6.32070310221778\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "\n",
    "main_start = time.time()\n",
    "\n",
    "for nest in n_estimators:\n",
    "    for lr in learning_rates:\n",
    "\n",
    "        df_train, df_test = split_series_byID(100, 0.8, df_db)\n",
    "        features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "        xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "        xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "        \n",
    "        clf_adaBoost = AdaBoostClassifier(base_estimator=base_estim, n_estimators=nest, learning_rate=lr)\n",
    "        \n",
    "        start_t = time.time()\n",
    "        \n",
    "        clf_adaBoost.fit(xtrain, ytrain)\n",
    "\n",
    "        end_t = time.time()\n",
    "        \n",
    "        print('==========================================')\n",
    "        print('Number of estimators:', nest)\n",
    "        print('Learning rate:', lr)\n",
    "        print('Training time (mins):', (end_t-start_t)/60)\n",
    "        print('Precision (score):', clf_adaBoost.score(xtest, ytest))\n",
    "        print('==========================================')\n",
    "        \n",
    "        clfs.append(clf_adaBoost)\n",
    "        \n",
    "\n",
    "main_end = time.time()\n",
    "print('==============================================================')\n",
    "print('Total time (hours):', (main_end-main_start)/(60*60))\n",
    "print('==============================================================')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
