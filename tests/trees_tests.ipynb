{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from preprocessing import *\n",
    "from plotting import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = group_datafiles_byID('../datasets/raw/HT_Sensor_metadata.dat', '../datasets/raw/HT_Sensor_dataset.dat')\n",
    "df_db = reclassify_series_samples(df_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing sklearn DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = split_series_byID(100, 0.75, df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(701805, 11)\n",
      "(701805,)\n",
      "(227186, 11)\n",
      "(227186,)\n"
     ]
    }
   ],
   "source": [
    "features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = DecisionTreeClassifier(\n",
    "                criterion='entropy',\n",
    "                splitter='best',\n",
    "                max_features='sqrt',\n",
    "                random_state=0)\n",
    "            # Default input args:\n",
    "            #    max_depth=None -> If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples\n",
    "            #    min_samples_split=2\n",
    "            #    min_samples_leaf=1\n",
    "            #    ccp_alpha=0.0 -> By default, no pruning is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (mins): 0.07512848774592082\n"
     ]
    }
   ],
   "source": [
    "start_t = time.time()\n",
    "\n",
    "clf_tree.fit(xtrain, ytrain)\n",
    "\n",
    "end_t = time.time()\n",
    "print('Training time (mins):', (end_t-start_t)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7461287227205902"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "print(clf_tree.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing RandomForest (ensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = group_datafiles_byID('../datasets/raw/HT_Sensor_metadata.dat', '../datasets/raw/HT_Sensor_dataset.dat')\n",
    "df_db = reclassify_series_samples(df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list = [2, 4, 6, 8, 10, 14, 18, 22, 26, 32, 36, 40]\n",
    "n_estimators_list = [400, 500, 700, 1000]\n",
    "criterions = ['entropy', 'gini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 2\n",
      "Criterion: gini\n",
      "Training time (mins): 6.274376936753591\n",
      "Precision (score): 0.82572384867891\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 5.355758766333262\n",
      "Precision (score): 0.8250252487058514\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 4.3957205533981325\n",
      "Precision (score): 0.8006146586511463\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 6.587088612715403\n",
      "Precision (score): 0.830885825237377\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 5.570846013228098\n",
      "Precision (score): 0.8388239826545058\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 9.296311287085215\n",
      "Precision (score): 0.7938500736418873\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 8.30868130127589\n",
      "Precision (score): 0.8073012898149703\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 13.147202316919962\n",
      "Precision (score): 0.8519079655674694\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 11.171217199166616\n",
      "Precision (score): 0.8534675867291059\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 7.344436502456665\n",
      "Precision (score): 0.8557942472694756\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 6.523063131173452\n",
      "Precision (score): 0.8236653467898551\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 9.697747317949931\n",
      "Precision (score): 0.8610006860450911\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 7.81781564950943\n",
      "Precision (score): 0.8545452844836455\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 13.41621394554774\n",
      "Precision (score): 0.8372852233676976\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 11.089528699715933\n",
      "Precision (score): 0.8188188095227039\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 19.107880850632984\n",
      "Precision (score): 0.8597149888972988\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 18.51077799399694\n",
      "Precision (score): 0.8325345596586974\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 8\n",
      "Criterion: entropy\n",
      "Training time (mins): 11.296044099330903\n",
      "Precision (score): 0.9009183583363586\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 8\n",
      "Criterion: gini\n",
      "Training time (mins): 9.272575398286184\n",
      "Precision (score): 0.8544559272707615\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 8\n",
      "Criterion: entropy\n",
      "Training time (mins): 13.878429333368937\n",
      "Precision (score): 0.8253371645514492\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 8\n",
      "Criterion: gini\n",
      "Training time (mins): 11.560842712720236\n",
      "Precision (score): 0.8026438825837443\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 8\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.382872068881987\n",
      "Precision (score): 0.8310640791423942\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 8\n",
      "Criterion: gini\n",
      "Training time (mins): 14.455410599708557\n",
      "Precision (score): 0.7959992140987037\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 8\n",
      "Criterion: entropy\n",
      "Training time (mins): 26.813397045930227\n",
      "Precision (score): 0.8576871035535041\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 8\n",
      "Criterion: gini\n",
      "Training time (mins): 24.597335477670033\n",
      "Precision (score): 0.8277659386749555\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 11.933628833293914\n",
      "Precision (score): 0.8019496883151332\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 10.155005248387655\n",
      "Precision (score): 0.8303129393768691\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 14.831617462635041\n",
      "Precision (score): 0.803713777030231\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 13.500326363245646\n",
      "Precision (score): 0.8093935466592699\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 22.15176858504613\n",
      "Precision (score): 0.8103893294526575\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 20.351263614495597\n",
      "Precision (score): 0.8366451660024742\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 31.385870317618053\n",
      "Precision (score): 0.7893321160538548\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 28.612787818908693\n",
      "Precision (score): 0.8438155293646623\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 14\n",
      "Criterion: entropy\n",
      "Training time (mins): 14.68951538403829\n",
      "Precision (score): 0.8384719142223543\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 14\n",
      "Criterion: gini\n",
      "Training time (mins): 14.105405366420745\n",
      "Precision (score): 0.8622737636164044\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 14\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.87949724992116\n",
      "Precision (score): 0.7571748478478891\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 14\n",
      "Criterion: gini\n",
      "Training time (mins): 17.604650568962096\n",
      "Precision (score): 0.7957882109268466\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 14\n",
      "Criterion: entropy\n",
      "Training time (mins): 26.34679125150045\n",
      "Precision (score): 0.7941923369249341\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 14\n",
      "Criterion: gini\n",
      "Training time (mins): 23.933551267782846\n",
      "Precision (score): 0.815925519364874\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 14\n",
      "Criterion: entropy\n",
      "Training time (mins): 37.51170394817988\n",
      "Precision (score): 0.8438593962836063\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 14\n",
      "Criterion: gini\n",
      "Training time (mins): 35.224063181877135\n",
      "Precision (score): 0.7815720644652476\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 18\n",
      "Criterion: entropy\n",
      "Training time (mins): 16.2227992494901\n",
      "Precision (score): 0.8211332662581177\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 18\n",
      "Criterion: gini\n",
      "Training time (mins): 14.905044051011403\n",
      "Precision (score): 0.8020904863514653\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 18\n",
      "Criterion: entropy\n",
      "Training time (mins): 19.608232017358144\n",
      "Precision (score): 0.7938552882689726\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 18\n",
      "Criterion: gini\n",
      "Training time (mins): 19.428412850697836\n",
      "Precision (score): 0.8252713549895567\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 18\n",
      "Criterion: entropy\n",
      "Training time (mins): 28.236671368281048\n",
      "Precision (score): 0.8413774211373973\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 18\n",
      "Criterion: gini\n",
      "Training time (mins): 26.612028364340464\n",
      "Precision (score): 0.8387357169698404\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 18\n",
      "Criterion: entropy\n",
      "Training time (mins): 39.657892020543414\n",
      "Precision (score): 0.7322617602130743\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 18\n",
      "Criterion: gini\n",
      "Training time (mins): 38.3241659005483\n",
      "Precision (score): 0.8328183781444115\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 22\n",
      "Criterion: entropy\n",
      "Training time (mins): 16.181909596920015\n",
      "Precision (score): 0.8439518462240496\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 22\n",
      "Criterion: gini\n",
      "Training time (mins): 16.157032334804533\n",
      "Precision (score): 0.8797954092567775\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 22\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.401815148194633\n",
      "Precision (score): 0.8156491785668311\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 22\n",
      "Criterion: gini\n",
      "Training time (mins): 20.928504212697348\n",
      "Precision (score): 0.8369281669529809\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 22\n",
      "Criterion: entropy\n",
      "Training time (mins): 31.08846568663915\n",
      "Precision (score): 0.7851257966809084\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 22\n",
      "Criterion: gini\n",
      "Training time (mins): 24.543841485182444\n",
      "Precision (score): 0.8218483112581275\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 22\n",
      "Criterion: entropy\n",
      "Training time (mins): 38.951690185070035\n",
      "Precision (score): 0.8023711179519152\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 22\n",
      "Criterion: gini\n",
      "Training time (mins): 40.32212035258611\n",
      "Precision (score): 0.7601177560258646\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 26\n",
      "Criterion: entropy\n",
      "Training time (mins): 15.988759617010752\n",
      "Precision (score): 0.8096645590063761\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 26\n",
      "Criterion: gini\n",
      "Training time (mins): 15.208831663926443\n",
      "Precision (score): 0.8662324071897143\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 26\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.171444602807362\n",
      "Precision (score): 0.8533343209145001\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 26\n",
      "Criterion: gini\n",
      "Training time (mins): 19.03989771207174\n",
      "Precision (score): 0.7946293376451092\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 26\n",
      "Criterion: entropy\n",
      "Training time (mins): 26.445433151721954\n",
      "Precision (score): 0.8417184722685891\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 26\n",
      "Criterion: gini\n",
      "Training time (mins): 29.066462667783103\n",
      "Precision (score): 0.8228491865085644\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 26\n",
      "Criterion: entropy\n",
      "Training time (mins): 41.083224415779114\n",
      "Precision (score): 0.8904761904761904\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 26\n",
      "Criterion: gini\n",
      "Training time (mins): 40.75688408613205\n",
      "Precision (score): 0.8409333164288297\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 32\n",
      "Criterion: entropy\n",
      "Training time (mins): 16.214678899447122\n",
      "Precision (score): 0.8121319225273429\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 32\n",
      "Criterion: gini\n",
      "Training time (mins): 17.175767612457275\n",
      "Precision (score): 0.7949288296126215\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 32\n",
      "Criterion: entropy\n",
      "Training time (mins): 20.979872715473174\n",
      "Precision (score): 0.8059125093159285\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 32\n",
      "Criterion: gini\n",
      "Training time (mins): 22.866595486799877\n",
      "Precision (score): 0.8549631987268749\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 32\n",
      "Criterion: entropy\n",
      "Training time (mins): 27.211875915527344\n",
      "Precision (score): 0.8477799703996053\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 32\n",
      "Criterion: gini\n",
      "Training time (mins): 25.160607437292736\n",
      "Precision (score): 0.8224215605256844\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 32\n",
      "Criterion: entropy\n",
      "Training time (mins): 42.96150778532028\n",
      "Precision (score): 0.887671117829848\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 32\n",
      "Criterion: gini\n",
      "Training time (mins): 49.587155656019846\n",
      "Precision (score): 0.8481588570456672\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 36\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.756543719768523\n",
      "Precision (score): 0.8588261092025437\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 36\n",
      "Criterion: gini\n",
      "Training time (mins): 15.886099580923716\n",
      "Precision (score): 0.8491512228659246\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 36\n",
      "Criterion: entropy\n",
      "Training time (mins): 19.701321947574616\n",
      "Precision (score): 0.8848147709788141\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 36\n",
      "Criterion: gini\n",
      "Training time (mins): 19.23148227930069\n",
      "Precision (score): 0.8137442261052884\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 36\n",
      "Criterion: entropy\n",
      "Training time (mins): 25.298999126752218\n",
      "Precision (score): 0.8452238798575017\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 36\n",
      "Criterion: gini\n",
      "Training time (mins): 28.251189935207368\n",
      "Precision (score): 0.8022400808788082\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 36\n",
      "Criterion: entropy\n",
      "Training time (mins): 47.44691472848256\n",
      "Precision (score): 0.8414715519216022\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 36\n",
      "Criterion: gini\n",
      "Training time (mins): 41.04220586617787\n",
      "Precision (score): 0.7968791117471896\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 40\n",
      "Criterion: entropy\n",
      "Training time (mins): 16.507924381891886\n",
      "Precision (score): 0.7995290514576291\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 40\n",
      "Criterion: gini\n",
      "Training time (mins): 16.79126339753469\n",
      "Precision (score): 0.7958682468097512\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 40\n",
      "Criterion: entropy\n",
      "Training time (mins): 20.838901182015736\n",
      "Precision (score): 0.8231577662247815\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 40\n",
      "Criterion: gini\n",
      "Training time (mins): 17.55820163488388\n",
      "Precision (score): 0.8514073003116902\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 40\n",
      "Criterion: entropy\n",
      "Training time (mins): 28.988572335243227\n",
      "Precision (score): 0.7782293431789898\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 40\n",
      "Criterion: gini\n",
      "Training time (mins): 31.353501796722412\n",
      "Precision (score): 0.8433087364489387\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 40\n",
      "Criterion: entropy\n",
      "Training time (mins): 43.28982339700063\n",
      "Precision (score): 0.7859979341214277\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 40\n",
      "Criterion: gini\n",
      "Training time (mins): 44.331841011842094\n",
      "Precision (score): 0.8497177017602126\n",
      "==========================================\n",
      "==================================================\n",
      "OVERALL TIME (hours): 32.631774254772395\n",
      "==================================================\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "main_start = time.time()\n",
    "\n",
    "for d in max_depth_list:\n",
    "    for nest in n_estimators_list:\n",
    "        for crit in criterions:\n",
    "\n",
    "            df_train, df_test = split_series_byID(100, 0.77, df_db)\n",
    "            features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "            xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "            xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "            \n",
    "            clf_randFor = RandomForestClassifier(\n",
    "                        n_estimators=nest,\n",
    "                        criterion=crit,\n",
    "                        max_depth=d,\n",
    "                        max_features='sqrt',\n",
    "                        random_state=0)\n",
    "\n",
    "            start_t = time.time()\n",
    "\n",
    "            clf_randFor.fit(xtrain, ytrain)\n",
    "\n",
    "            end_t = time.time()\n",
    "            print('==========================================')\n",
    "            print('Number of estimators:',nest)\n",
    "            print('Max depth:', d)\n",
    "            print('Criterion:', crit)\n",
    "            print('Training time (mins):', (end_t-start_t)/60)\n",
    "            print('Precision (score):', clf_randFor.score(xtest, ytest))\n",
    "            print('==========================================')\n",
    "\n",
    "main_end = time.time()\n",
    "\n",
    "print('==================================================')\n",
    "print('OVERALL TIME (hours):', (main_end-main_start)/(60*60))\n",
    "print('==================================================')\n",
    "print('==================================================')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Number of estimators: 5000\n",
      "Max depth: 7\n",
      "Criterion: entropy\n",
      "Training time (mins): 132.90388695001602\n",
      "Precision (score): 0.8471366322797279\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = split_series_byID(100, 0.77, df_db)\n",
    "features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "\n",
    "clf_randFor = RandomForestClassifier(\n",
    "            n_estimators=5000,\n",
    "            criterion='entropy',\n",
    "            max_depth=7,\n",
    "            max_features='sqrt',\n",
    "            random_state=0)\n",
    "\n",
    "start_t = time.time()\n",
    "\n",
    "clf_randFor.fit(xtrain, ytrain)\n",
    "\n",
    "end_t = time.time()\n",
    "print('==========================================')\n",
    "print('Number of estimators:',5000)\n",
    "print('Max depth:', 7)\n",
    "print('Criterion:', 'entropy')\n",
    "print('Training time (mins):', (end_t-start_t)/60)\n",
    "print('Precision (score):', clf_randFor.score(xtest, ytest))\n",
    "print('==========================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting with AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = group_datafiles_byID('../datasets/preprocessed/HT_Sensor_prep_metadata.dat',\n",
    "                             '../datasets/preprocessed/HT_Sensor_prep_dataset.dat')\n",
    "df_db = reclassify_series_samples(df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estim = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">===============================================================<\n",
      "Training time (mins): 60.569030567010245\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.789080459770115\n",
      "\tReal banana percentage: 0.11267651888341544\n",
      "\tReal wine percentage: 0.09824302134646962\n",
      "------------------------------------------\n",
      "Accuracy: 0.8548440065681445\n",
      "Recall on background: 0.9833732181874935\n",
      "Recall on banana: 0.0003886136209074128\n",
      "Recall on wine: 0.8024959607777592\n",
      "F1-score: 0.8047925002083012\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 59.598216251532236\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7201993506803027\n",
      "\tReal banana percentage: 0.17016307139868547\n",
      "\tReal wine percentage: 0.1096375779210118\n",
      "------------------------------------------\n",
      "Accuracy: 0.6832262609036454\n",
      "Recall on background: 0.8862725487744791\n",
      "Recall on banana: 0.06987456814715677\n",
      "Recall on wine: 0.3013864064537945\n",
      "F1-score: 0.6381393785021852\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 60.071112449963884\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7574008659690521\n",
      "\tReal banana percentage: 0.10822057162136603\n",
      "\tReal wine percentage: 0.1343785624095819\n",
      "------------------------------------------\n",
      "Accuracy: 0.7937674765743614\n",
      "Recall on background: 0.9345041238644187\n",
      "Recall on banana: 0.09093056211620218\n",
      "Recall on wine: 0.5665538098679956\n",
      "F1-score: 0.7636196205886451\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 59.92300613721212\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7039206573752994\n",
      "\tReal banana percentage: 0.09372909314689315\n",
      "\tReal wine percentage: 0.20235024947780744\n",
      "------------------------------------------\n",
      "Accuracy: 0.7602204188775796\n",
      "Recall on background: 0.9776325144739324\n",
      "Recall on banana: 0.05399662180569934\n",
      "Recall on wine: 0.33102821664731713\n",
      "F1-score: 0.7072306030993333\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 61.11980686982473\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7847512936206719\n",
      "\tReal banana percentage: 0.09384654645360611\n",
      "\tReal wine percentage: 0.12140215992572201\n",
      "------------------------------------------\n",
      "Accuracy: 0.7967291622550536\n",
      "Recall on background: 0.9495052930187504\n",
      "Recall on banana: 0.010414255959268688\n",
      "Recall on wine: 0.41701328324164766\n",
      "F1-score: 0.7575969071414098\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 60.92420493364334\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.826837416481069\n",
      "\tReal banana percentage: 0.0723776677406102\n",
      "\tReal wine percentage: 0.10078491577832076\n",
      "------------------------------------------\n",
      "Accuracy: 0.8474279412718663\n",
      "Recall on background: 0.9499983655323461\n",
      "Recall on banana: 0.010232280230039584\n",
      "Recall on wine: 0.6071658442394336\n",
      "F1-score: 0.8247525403720225\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 61.82652633190155\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7826759990868037\n",
      "\tReal banana percentage: 0.053878578309361935\n",
      "\tReal wine percentage: 0.16344542260383432\n",
      "------------------------------------------\n",
      "Accuracy: 0.8633657963461013\n",
      "Recall on background: 0.9874075128059192\n",
      "Recall on banana: 0.05177759404712691\n",
      "Recall on wine: 0.5369127516778524\n",
      "F1-score: 0.8354512230624402\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 61.42935188611349\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7764041867615779\n",
      "\tReal banana percentage: 0.15700882421077017\n",
      "\tReal wine percentage: 0.066586989027652\n",
      "------------------------------------------\n",
      "Accuracy: 0.780073921192848\n",
      "Recall on background: 0.9471938913904411\n",
      "Recall on banana: 0.07028604003889877\n",
      "Recall on wine: 0.5051000237210406\n",
      "F1-score: 0.7363212096044928\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 61.434492532412214\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7974572090827601\n",
      "\tReal banana percentage: 0.11630324664647568\n",
      "\tReal wine percentage: 0.08623954427076427\n",
      "------------------------------------------\n",
      "Accuracy: 0.80648480637342\n",
      "Recall on background: 0.9686259120567753\n",
      "Recall on banana: 0.038308934190723766\n",
      "Recall on wine: 0.34313303401193185\n",
      "F1-score: 0.7552345836442362\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 60.51603644688924\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7524589534430833\n",
      "\tReal banana percentage: 0.19429160746709967\n",
      "\tReal wine percentage: 0.05324943908981694\n",
      "------------------------------------------\n",
      "Accuracy: 0.7657123422182969\n",
      "Recall on background: 0.9665957074536335\n",
      "Recall on banana: 0.021147439155231804\n",
      "Recall on wine: 0.6437622334397857\n",
      "F1-score: 0.6893017652990139\n",
      "==============================================\n",
      ">===============================================================<\n",
      "==============================================================\n",
      "Total time (hours): 10.203501628107494\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "\n",
    "store_data = []\n",
    "\n",
    "main_start = time.time()\n",
    "\n",
    "for i in range(10):\n",
    "    df_train, df_test = split_series_byID(100, 0.8, df_db)\n",
    "    xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "    xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "\n",
    "    clf_boost = AdaBoostClassifier(base_estimator=base_estim, n_estimators=500, learning_rate=0.1)\n",
    "\n",
    "    start_t = time.time()\n",
    "\n",
    "    clf_boost.fit(xtrain, ytrain)\n",
    "\n",
    "    end_t = time.time()\n",
    "    print('>===============================================================<')\n",
    "    print('Training time (mins):', (end_t-start_t)/60)\n",
    "    y_pred = clf_boost.predict(xtest)\n",
    "    metric_report(ytest, y_pred)\n",
    "    print('>===============================================================<')\n",
    "    test_ids = list(set(df_test['id']))\n",
    "    data = [i, clf_boost, test_ids]\n",
    "    store_data.append(data)\n",
    "                \n",
    "main_end = time.time()\n",
    "print('==============================================================')\n",
    "print('Total time (hours):', (main_end-main_start)/(60*60))\n",
    "print('==============================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
       "                     learning_rate=0.1, n_estimators=500),\n",
       "  [3,\n",
       "   4,\n",
       "   15,\n",
       "   25,\n",
       "   29,\n",
       "   34,\n",
       "   36,\n",
       "   39,\n",
       "   43,\n",
       "   47,\n",
       "   55,\n",
       "   65,\n",
       "   70,\n",
       "   73,\n",
       "   74,\n",
       "   76,\n",
       "   87,\n",
       "   89,\n",
       "   92,\n",
       "   94]],\n",
       " [6,\n",
       "  AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
       "                     learning_rate=0.1, n_estimators=500),\n",
       "  [2,\n",
       "   4,\n",
       "   14,\n",
       "   19,\n",
       "   25,\n",
       "   27,\n",
       "   29,\n",
       "   31,\n",
       "   42,\n",
       "   47,\n",
       "   52,\n",
       "   64,\n",
       "   67,\n",
       "   69,\n",
       "   72,\n",
       "   74,\n",
       "   76,\n",
       "   79,\n",
       "   80,\n",
       "   82]]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data = [store_data[0], store_data[6]]\n",
    "main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/best_adaBoost.pkl', 'wb') as f:\n",
    "    pickle.dump(main_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=0.1, n_estimators=500), [3, 4, 15, 25, 29, 34, 36, 39, 43, 47, 55, 65, 70, 73, 74, 76, 87, 89, 92, 94]], [6, AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=0.1, n_estimators=500), [2, 4, 14, 19, 25, 27, 29, 31, 42, 47, 52, 64, 67, 69, 72, 74, 76, 79, 80, 82]]]\n"
     ]
    }
   ],
   "source": [
    "with open('../models/best_adaBoost.pkl', 'rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Random Forest with windows"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_df = pd.read_pickle('../datasets/preprocessed/window120_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">===============================================================<\n",
      "Training time (mins): 22.713820616404217\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7698813088573536\n",
      "\tReal banana percentage: 0.10432669357288547\n",
      "\tReal wine percentage: 0.1257919975697609\n",
      "------------------------------------------\n",
      "Accuracy: 0.8702371652996571\n",
      "Recall on background: 0.9735701753767888\n",
      "Recall on banana: 0.06036813643926789\n",
      "Recall on wine: 0.9094829444995473\n",
      "F1-score: 0.8339762656277273\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 24.740298982461294\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.8015699016314148\n",
      "\tReal banana percentage: 0.10330541579260054\n",
      "\tReal wine percentage: 0.09512468257598461\n",
      "------------------------------------------\n",
      "Accuracy: 0.8653806722291446\n",
      "Recall on background: 0.9561658391326306\n",
      "Recall on banana: 0.09186218128149015\n",
      "Recall on wine: 0.9404189465539159\n",
      "F1-score: 0.8335283702251732\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "0.8345333921117225\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "0.794929807214243\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "0.7790383390431594\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 23.694669381777445\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.8352543046512444\n",
      "\tReal banana percentage: 0.08872315803008872\n",
      "\tReal wine percentage: 0.07602253731866693\n",
      "------------------------------------------\n",
      "Accuracy: 0.8789554280103336\n",
      "Recall on background: 0.9903363726059605\n",
      "Recall on banana: 0.012516469038208168\n",
      "Recall on wine: 0.6664103944030138\n",
      "F1-score: 0.8388046209678555\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "0.8398319408380565\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "0.8379335140217933\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 26.28688443104426\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.794270111986071\n",
      "\tReal banana percentage: 0.04049814298716202\n",
      "\tReal wine percentage: 0.165231745026767\n",
      "------------------------------------------\n",
      "Accuracy: 0.8756564554514774\n",
      "Recall on background: 0.9894949609975516\n",
      "Recall on banana: 0.0\n",
      "Recall on wine: 0.5430565534229703\n",
      "F1-score: 0.8510990803675788\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "0.8051716923763563\n",
      ">===============================================================<\n",
      "==============================================================\n",
      "Total time (hours): 3.9122777555386223\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity',\n",
    "            'R1_mean', 'R2_mean', 'R3_mean', 'R4_mean', 'R5_mean', 'R6_mean', 'R7_mean',\n",
    "            'R8_mean', 'Temp._mean', 'Humidity_mean', 'R1_std', 'R2_std', 'R3_std', 'R4_std',\n",
    "            'R5_std', 'R6_std', 'R7_std', 'R8_std', 'Temp._std', 'Humidity_std']\n",
    "\n",
    "store_data = []\n",
    "\n",
    "main_start = time.time()\n",
    "\n",
    "for i in range(10):\n",
    "    df_train, df_test = split_series_byID(100, 0.8, win_df)\n",
    "    xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "    xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "\n",
    "    clf_rf = RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=7)\n",
    "\n",
    "    start_t = time.time()\n",
    "    clf_rf.fit(xtrain, ytrain)\n",
    "    end_t = time.time()\n",
    "\n",
    "    sc = clf_rf.score(xtest, ytest)\n",
    "    if sc > 0.85:\n",
    "        print('>===============================================================<')\n",
    "        print('Training time (mins):', (end_t-start_t)/60)\n",
    "        y_pred = clf_rf.predict(xtest)\n",
    "        metric_report(ytest, y_pred)\n",
    "        print('>===============================================================<')\n",
    "        test_ids = list(set(df_test['id']))\n",
    "        data = [i, clf_rf, test_ids]\n",
    "        store_data.append(data)\n",
    "    else:\n",
    "        print('>===============================================================<')\n",
    "        print(sc)\n",
    "        print('>===============================================================<')\n",
    "                \n",
    "main_end = time.time()\n",
    "print('==============================================================')\n",
    "print('Total time (hours):', (main_end-main_start)/(60*60))\n",
    "print('==============================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = [store_data[0], store_data[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/randFor_win120_goodRecallWine.pkl', 'wb') as f:\n",
    "    pickle.dump(main_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}