{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from preprocessing import *\n",
    "from plotting import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = group_datafiles_byID('../datasets/raw/HT_Sensor_metadata.dat', '../datasets/raw/HT_Sensor_dataset.dat')\n",
    "df_db = reclassify_series_samples(df_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing sklearn DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = split_series_byID(100, 0.75, df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(701805, 11)\n",
      "(701805,)\n",
      "(227186, 11)\n",
      "(227186,)\n"
     ]
    }
   ],
   "source": [
    "features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = DecisionTreeClassifier(\n",
    "                criterion='entropy',\n",
    "                splitter='best',\n",
    "                max_features='sqrt',\n",
    "                random_state=0)\n",
    "            # Default input args:\n",
    "            #    max_depth=None -> If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples\n",
    "            #    min_samples_split=2\n",
    "            #    min_samples_leaf=1\n",
    "            #    ccp_alpha=0.0 -> By default, no pruning is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (mins): 0.07512848774592082\n"
     ]
    }
   ],
   "source": [
    "start_t = time.time()\n",
    "\n",
    "clf_tree.fit(xtrain, ytrain)\n",
    "\n",
    "end_t = time.time()\n",
    "print('Training time (mins):', (end_t-start_t)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7461287227205902"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "print(clf_tree.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing RandomForest (ensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = group_datafiles_byID('../datasets/raw/HT_Sensor_metadata.dat', '../datasets/raw/HT_Sensor_dataset.dat')\n",
    "df_db = reclassify_series_samples(df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list = [2, 4, 6, 8, 10, 14, 18, 22, 26, 32, 36, 40]\n",
    "n_estimators_list = [400, 500, 700, 1000]\n",
    "criterions = ['entropy', 'gini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 2\n",
      "Criterion: gini\n",
      "Training time (mins): 6.274376936753591\n",
      "Precision (score): 0.82572384867891\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 5.355758766333262\n",
      "Precision (score): 0.8250252487058514\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 4.3957205533981325\n",
      "Precision (score): 0.8006146586511463\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 6.587088612715403\n",
      "Precision (score): 0.830885825237377\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 5.570846013228098\n",
      "Precision (score): 0.8388239826545058\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 9.296311287085215\n",
      "Precision (score): 0.7938500736418873\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 8.30868130127589\n",
      "Precision (score): 0.8073012898149703\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 4\n",
      "Criterion: entropy\n",
      "Training time (mins): 13.147202316919962\n",
      "Precision (score): 0.8519079655674694\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 4\n",
      "Criterion: gini\n",
      "Training time (mins): 11.171217199166616\n",
      "Precision (score): 0.8534675867291059\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 7.344436502456665\n",
      "Precision (score): 0.8557942472694756\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 6.523063131173452\n",
      "Precision (score): 0.8236653467898551\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 9.697747317949931\n",
      "Precision (score): 0.8610006860450911\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 7.81781564950943\n",
      "Precision (score): 0.8545452844836455\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 13.41621394554774\n",
      "Precision (score): 0.8372852233676976\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 11.089528699715933\n",
      "Precision (score): 0.8188188095227039\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 6\n",
      "Criterion: entropy\n",
      "Training time (mins): 19.107880850632984\n",
      "Precision (score): 0.8597149888972988\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 6\n",
      "Criterion: gini\n",
      "Training time (mins): 18.51077799399694\n",
      "Precision (score): 0.8325345596586974\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 8\n",
      "Criterion: entropy\n",
      "Training time (mins): 11.296044099330903\n",
      "Precision (score): 0.9009183583363586\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 8\n",
      "Criterion: gini\n",
      "Training time (mins): 9.272575398286184\n",
      "Precision (score): 0.8544559272707615\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 8\n",
      "Criterion: entropy\n",
      "Training time (mins): 13.878429333368937\n",
      "Precision (score): 0.8253371645514492\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 8\n",
      "Criterion: gini\n",
      "Training time (mins): 11.560842712720236\n",
      "Precision (score): 0.8026438825837443\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 8\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.382872068881987\n",
      "Precision (score): 0.8310640791423942\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 8\n",
      "Criterion: gini\n",
      "Training time (mins): 14.455410599708557\n",
      "Precision (score): 0.7959992140987037\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 8\n",
      "Criterion: entropy\n",
      "Training time (mins): 26.813397045930227\n",
      "Precision (score): 0.8576871035535041\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 8\n",
      "Criterion: gini\n",
      "Training time (mins): 24.597335477670033\n",
      "Precision (score): 0.8277659386749555\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 11.933628833293914\n",
      "Precision (score): 0.8019496883151332\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 10.155005248387655\n",
      "Precision (score): 0.8303129393768691\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 14.831617462635041\n",
      "Precision (score): 0.803713777030231\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 13.500326363245646\n",
      "Precision (score): 0.8093935466592699\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 22.15176858504613\n",
      "Precision (score): 0.8103893294526575\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 20.351263614495597\n",
      "Precision (score): 0.8366451660024742\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 10\n",
      "Criterion: entropy\n",
      "Training time (mins): 31.385870317618053\n",
      "Precision (score): 0.7893321160538548\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 10\n",
      "Criterion: gini\n",
      "Training time (mins): 28.612787818908693\n",
      "Precision (score): 0.8438155293646623\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 14\n",
      "Criterion: entropy\n",
      "Training time (mins): 14.68951538403829\n",
      "Precision (score): 0.8384719142223543\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 14\n",
      "Criterion: gini\n",
      "Training time (mins): 14.105405366420745\n",
      "Precision (score): 0.8622737636164044\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 14\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.87949724992116\n",
      "Precision (score): 0.7571748478478891\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 14\n",
      "Criterion: gini\n",
      "Training time (mins): 17.604650568962096\n",
      "Precision (score): 0.7957882109268466\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 14\n",
      "Criterion: entropy\n",
      "Training time (mins): 26.34679125150045\n",
      "Precision (score): 0.7941923369249341\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 14\n",
      "Criterion: gini\n",
      "Training time (mins): 23.933551267782846\n",
      "Precision (score): 0.815925519364874\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 14\n",
      "Criterion: entropy\n",
      "Training time (mins): 37.51170394817988\n",
      "Precision (score): 0.8438593962836063\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 14\n",
      "Criterion: gini\n",
      "Training time (mins): 35.224063181877135\n",
      "Precision (score): 0.7815720644652476\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 18\n",
      "Criterion: entropy\n",
      "Training time (mins): 16.2227992494901\n",
      "Precision (score): 0.8211332662581177\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 18\n",
      "Criterion: gini\n",
      "Training time (mins): 14.905044051011403\n",
      "Precision (score): 0.8020904863514653\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 18\n",
      "Criterion: entropy\n",
      "Training time (mins): 19.608232017358144\n",
      "Precision (score): 0.7938552882689726\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 18\n",
      "Criterion: gini\n",
      "Training time (mins): 19.428412850697836\n",
      "Precision (score): 0.8252713549895567\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 18\n",
      "Criterion: entropy\n",
      "Training time (mins): 28.236671368281048\n",
      "Precision (score): 0.8413774211373973\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 18\n",
      "Criterion: gini\n",
      "Training time (mins): 26.612028364340464\n",
      "Precision (score): 0.8387357169698404\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 18\n",
      "Criterion: entropy\n",
      "Training time (mins): 39.657892020543414\n",
      "Precision (score): 0.7322617602130743\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 18\n",
      "Criterion: gini\n",
      "Training time (mins): 38.3241659005483\n",
      "Precision (score): 0.8328183781444115\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 22\n",
      "Criterion: entropy\n",
      "Training time (mins): 16.181909596920015\n",
      "Precision (score): 0.8439518462240496\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 22\n",
      "Criterion: gini\n",
      "Training time (mins): 16.157032334804533\n",
      "Precision (score): 0.8797954092567775\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 22\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.401815148194633\n",
      "Precision (score): 0.8156491785668311\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 22\n",
      "Criterion: gini\n",
      "Training time (mins): 20.928504212697348\n",
      "Precision (score): 0.8369281669529809\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 22\n",
      "Criterion: entropy\n",
      "Training time (mins): 31.08846568663915\n",
      "Precision (score): 0.7851257966809084\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 22\n",
      "Criterion: gini\n",
      "Training time (mins): 24.543841485182444\n",
      "Precision (score): 0.8218483112581275\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 22\n",
      "Criterion: entropy\n",
      "Training time (mins): 38.951690185070035\n",
      "Precision (score): 0.8023711179519152\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 22\n",
      "Criterion: gini\n",
      "Training time (mins): 40.32212035258611\n",
      "Precision (score): 0.7601177560258646\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 26\n",
      "Criterion: entropy\n",
      "Training time (mins): 15.988759617010752\n",
      "Precision (score): 0.8096645590063761\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 26\n",
      "Criterion: gini\n",
      "Training time (mins): 15.208831663926443\n",
      "Precision (score): 0.8662324071897143\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 26\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.171444602807362\n",
      "Precision (score): 0.8533343209145001\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 26\n",
      "Criterion: gini\n",
      "Training time (mins): 19.03989771207174\n",
      "Precision (score): 0.7946293376451092\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 26\n",
      "Criterion: entropy\n",
      "Training time (mins): 26.445433151721954\n",
      "Precision (score): 0.8417184722685891\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 26\n",
      "Criterion: gini\n",
      "Training time (mins): 29.066462667783103\n",
      "Precision (score): 0.8228491865085644\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 26\n",
      "Criterion: entropy\n",
      "Training time (mins): 41.083224415779114\n",
      "Precision (score): 0.8904761904761904\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 26\n",
      "Criterion: gini\n",
      "Training time (mins): 40.75688408613205\n",
      "Precision (score): 0.8409333164288297\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 32\n",
      "Criterion: entropy\n",
      "Training time (mins): 16.214678899447122\n",
      "Precision (score): 0.8121319225273429\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 32\n",
      "Criterion: gini\n",
      "Training time (mins): 17.175767612457275\n",
      "Precision (score): 0.7949288296126215\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 32\n",
      "Criterion: entropy\n",
      "Training time (mins): 20.979872715473174\n",
      "Precision (score): 0.8059125093159285\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 32\n",
      "Criterion: gini\n",
      "Training time (mins): 22.866595486799877\n",
      "Precision (score): 0.8549631987268749\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 32\n",
      "Criterion: entropy\n",
      "Training time (mins): 27.211875915527344\n",
      "Precision (score): 0.8477799703996053\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 32\n",
      "Criterion: gini\n",
      "Training time (mins): 25.160607437292736\n",
      "Precision (score): 0.8224215605256844\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 32\n",
      "Criterion: entropy\n",
      "Training time (mins): 42.96150778532028\n",
      "Precision (score): 0.887671117829848\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 32\n",
      "Criterion: gini\n",
      "Training time (mins): 49.587155656019846\n",
      "Precision (score): 0.8481588570456672\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 36\n",
      "Criterion: entropy\n",
      "Training time (mins): 18.756543719768523\n",
      "Precision (score): 0.8588261092025437\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 36\n",
      "Criterion: gini\n",
      "Training time (mins): 15.886099580923716\n",
      "Precision (score): 0.8491512228659246\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 36\n",
      "Criterion: entropy\n",
      "Training time (mins): 19.701321947574616\n",
      "Precision (score): 0.8848147709788141\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 36\n",
      "Criterion: gini\n",
      "Training time (mins): 19.23148227930069\n",
      "Precision (score): 0.8137442261052884\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 36\n",
      "Criterion: entropy\n",
      "Training time (mins): 25.298999126752218\n",
      "Precision (score): 0.8452238798575017\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 36\n",
      "Criterion: gini\n",
      "Training time (mins): 28.251189935207368\n",
      "Precision (score): 0.8022400808788082\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 36\n",
      "Criterion: entropy\n",
      "Training time (mins): 47.44691472848256\n",
      "Precision (score): 0.8414715519216022\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 36\n",
      "Criterion: gini\n",
      "Training time (mins): 41.04220586617787\n",
      "Precision (score): 0.7968791117471896\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 40\n",
      "Criterion: entropy\n",
      "Training time (mins): 16.507924381891886\n",
      "Precision (score): 0.7995290514576291\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 400\n",
      "Max depth: 40\n",
      "Criterion: gini\n",
      "Training time (mins): 16.79126339753469\n",
      "Precision (score): 0.7958682468097512\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 40\n",
      "Criterion: entropy\n",
      "Training time (mins): 20.838901182015736\n",
      "Precision (score): 0.8231577662247815\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Max depth: 40\n",
      "Criterion: gini\n",
      "Training time (mins): 17.55820163488388\n",
      "Precision (score): 0.8514073003116902\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 40\n",
      "Criterion: entropy\n",
      "Training time (mins): 28.988572335243227\n",
      "Precision (score): 0.7782293431789898\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 700\n",
      "Max depth: 40\n",
      "Criterion: gini\n",
      "Training time (mins): 31.353501796722412\n",
      "Precision (score): 0.8433087364489387\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 40\n",
      "Criterion: entropy\n",
      "Training time (mins): 43.28982339700063\n",
      "Precision (score): 0.7859979341214277\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Max depth: 40\n",
      "Criterion: gini\n",
      "Training time (mins): 44.331841011842094\n",
      "Precision (score): 0.8497177017602126\n",
      "==========================================\n",
      "==================================================\n",
      "OVERALL TIME (hours): 32.631774254772395\n",
      "==================================================\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "main_start = time.time()\n",
    "\n",
    "for d in max_depth_list:\n",
    "    for nest in n_estimators_list:\n",
    "        for crit in criterions:\n",
    "\n",
    "            df_train, df_test = split_series_byID(100, 0.77, df_db)\n",
    "            features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "            xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "            xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "            \n",
    "            clf_randFor = RandomForestClassifier(\n",
    "                        n_estimators=nest,\n",
    "                        criterion=crit,\n",
    "                        max_depth=d,\n",
    "                        max_features='sqrt',\n",
    "                        random_state=0)\n",
    "\n",
    "            start_t = time.time()\n",
    "\n",
    "            clf_randFor.fit(xtrain, ytrain)\n",
    "\n",
    "            end_t = time.time()\n",
    "            print('==========================================')\n",
    "            print('Number of estimators:',nest)\n",
    "            print('Max depth:', d)\n",
    "            print('Criterion:', crit)\n",
    "            print('Training time (mins):', (end_t-start_t)/60)\n",
    "            print('Precision (score):', clf_randFor.score(xtest, ytest))\n",
    "            print('==========================================')\n",
    "\n",
    "main_end = time.time()\n",
    "\n",
    "print('==================================================')\n",
    "print('OVERALL TIME (hours):', (main_end-main_start)/(60*60))\n",
    "print('==================================================')\n",
    "print('==================================================')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Number of estimators: 5000\n",
      "Max depth: 7\n",
      "Criterion: entropy\n",
      "Training time (mins): 132.90388695001602\n",
      "Precision (score): 0.8471366322797279\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = split_series_byID(100, 0.77, df_db)\n",
    "features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "\n",
    "clf_randFor = RandomForestClassifier(\n",
    "            n_estimators=5000,\n",
    "            criterion='entropy',\n",
    "            max_depth=7,\n",
    "            max_features='sqrt',\n",
    "            random_state=0)\n",
    "\n",
    "start_t = time.time()\n",
    "\n",
    "clf_randFor.fit(xtrain, ytrain)\n",
    "\n",
    "end_t = time.time()\n",
    "print('==========================================')\n",
    "print('Number of estimators:',5000)\n",
    "print('Max depth:', 7)\n",
    "print('Criterion:', 'entropy')\n",
    "print('Training time (mins):', (end_t-start_t)/60)\n",
    "print('Precision (score):', clf_randFor.score(xtest, ytest))\n",
    "print('==========================================')"
   ]
  },
  {
   "source": [
    "# Boosting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = group_datafiles_byID('../datasets/preprocessed/HT_Sensor_prep_metadata.dat',\n",
    "                             '../datasets/preprocessed/HT_Sensor_prep_dataset.dat')\n",
    "df_db = reclassify_series_samples(df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">===============================================================<\n",
      "Training time (mins): 114.32665293216705\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7832136826889204\n",
      "\tReal banana percentage: 0.07895727803894416\n",
      "\tReal wine percentage: 0.13782903927213536\n",
      "------------------------------------------\n",
      "Accuracy: 0.7995213974223485\n",
      "Recall on background: 0.9107814475041294\n",
      "Recall on banana: 7.692307692307693e-05\n",
      "Recall on wine: 0.6252588904067333\n",
      "F1-score: 0.7765330941188221\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 117.35292978286743\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7260663857470244\n",
      "\tReal banana percentage: 0.1543843529871474\n",
      "\tReal wine percentage: 0.11954926126582813\n",
      "------------------------------------------\n",
      "Accuracy: 0.7747151200245013\n",
      "Recall on background: 0.9276077992160057\n",
      "Recall on banana: 0.05120224373225707\n",
      "Recall on wine: 0.7804770318021201\n",
      "F1-score: 0.7313554938749394\n",
      "==============================================\n",
      ">===============================================================<\n",
      ">===============================================================<\n",
      "Training time (mins): 116.85685683091482\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7660001535576005\n",
      "\tReal banana percentage: 0.15205492974739776\n",
      "\tReal wine percentage: 0.0819449166950017\n",
      "------------------------------------------\n",
      "Accuracy: 0.8188733259479439\n",
      "Recall on background: 0.9675100591377064\n",
      "Recall on banana: 0.13312414340330375\n",
      "Recall on wine: 0.7019140677285504\n",
      "F1-score: 0.7796346477447892\n",
      "==============================================\n",
      ">===============================================================<\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b827c00212d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mstart_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mclf_boost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mend_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    498\u001b[0m         n_stages = self._fit_stages(\n\u001b[1;32m    499\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m    555\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[1;32m    556\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 212\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "\n",
    "store_data = []\n",
    "\n",
    "main_start = time.time()\n",
    "\n",
    "for i in range(10):\n",
    "    df_train, df_test = split_series_byID(100, 0.8, df_db)\n",
    "    xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "    xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "\n",
    "    clf_boost = GradientBoostingClassifier(\n",
    "                    loss='deviance',\n",
    "                    learning_rate=0.01,\n",
    "                    n_estimators=600,\n",
    "                    max_depth=7,\n",
    "                    random_state=0)\n",
    "\n",
    "    start_t = time.time()\n",
    "\n",
    "    clf_boost.fit(xtrain, ytrain)\n",
    "\n",
    "    end_t = time.time()\n",
    "    print('>===============================================================<')\n",
    "    print('Training time (mins):', (end_t-start_t)/60)\n",
    "    y_pred = clf_boost.predict(xtest)\n",
    "    metric_report(ytest, y_pred)\n",
    "    print('>===============================================================<')\n",
    "    test_ids = list(set(df_test['id']))\n",
    "    data = [i, clf_boost, test_ids]\n",
    "    store_data.append(data)\n",
    "                \n",
    "main_end = time.time()\n",
    "print('==============================================================')\n",
    "print('Total time (hours):', (main_end-main_start)/(60*60))\n",
    "print('==============================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting with AdaBoost classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we are gonna store classifiers to study them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estim = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [500, 1000]\n",
    "learning_rates = [0.1, 0.01, 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Number of estimators: 500\n",
      "Learning rate: 0.1\n",
      "Training time (mins): 43.583362050851186\n",
      "Precision (score): 0.8719164179104477\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Learning rate: 0.01\n",
      "Training time (mins): 40.7228889465332\n",
      "Precision (score): 0.7880553532410779\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 500\n",
      "Learning rate: 0.001\n",
      "Training time (mins): 42.52133306662242\n",
      "Precision (score): 0.8655926945044344\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Learning rate: 0.1\n",
      "Training time (mins): 83.51484416325887\n",
      "Precision (score): 0.7885299402295479\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Learning rate: 0.01\n",
      "Training time (mins): 83.1132468978564\n",
      "Precision (score): 0.8277351931081416\n",
      "==========================================\n",
      "==========================================\n",
      "Number of estimators: 1000\n",
      "Learning rate: 0.001\n",
      "Training time (mins): 83.40477879842122\n",
      "Precision (score): 0.8240472648355809\n",
      "==========================================\n",
      "==============================================================\n",
      "Total time (hours): 6.32070310221778\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "\n",
    "main_start = time.time()\n",
    "\n",
    "for nest in n_estimators:\n",
    "    for lr in learning_rates:\n",
    "\n",
    "        df_train, df_test = split_series_byID(100, 0.8, df_db)\n",
    "        features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "        xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "        xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "        \n",
    "        clf_adaBoost = AdaBoostClassifier(base_estimator=base_estim, n_estimators=nest, learning_rate=lr)\n",
    "        \n",
    "        start_t = time.time()\n",
    "        \n",
    "        clf_adaBoost.fit(xtrain, ytrain)\n",
    "\n",
    "        end_t = time.time()\n",
    "        \n",
    "        print('==========================================')\n",
    "        print('Number of estimators:', nest)\n",
    "        print('Learning rate:', lr)\n",
    "        print('Training time (mins):', (end_t-start_t)/60)\n",
    "        print('Precision (score):', clf_adaBoost.score(xtest, ytest))\n",
    "        print('==========================================')\n",
    "        \n",
    "        clfs.append(clf_adaBoost)\n",
    "        \n",
    "\n",
    "main_end = time.time()\n",
    "print('==============================================================')\n",
    "print('Total time (hours):', (main_end-main_start)/(60*60))\n",
    "print('==============================================================')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}