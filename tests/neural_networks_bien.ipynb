{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from time import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from preprocessing import *\n",
    "from utils import *\n",
    "from plotting import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varía ciertos hiperparámetros e imprime los resultados más relevantes\n",
    "def hyper_sim(df,num_val,n_hid_layers,n_neur,alpha,features,over_dict=None,under_dict=None):\n",
    "    errs_acc = []\n",
    "    errs_f1 = []\n",
    "    rec_ban = []\n",
    "    loss = []\n",
    "    for i in range(num_val):\n",
    "        df_train, df_test = split_series_byID(0.75, df)\n",
    "        df_train, df_test = norm_train_test(df_train,df_test,features_to_norm=features)\n",
    "        xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "        if over_dict and under_dict:\n",
    "            over_sampling = SMOTE(sampling_strategy=over_dict)\n",
    "            under_sampling = RandomUnderSampler(sampling_strategy=under_dict)\n",
    "            xtrain, ytrain = over_sampling.fit_resample(xtrain, ytrain)\n",
    "            xtrain, ytrain = under_sampling.fit_resample(xtrain, ytrain)\n",
    "        xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "        \n",
    "        tup = []\n",
    "        for i in range(n_hid_layers):\n",
    "            tup.append(n_neur)\n",
    "        tup = tuple(tup)\n",
    "\n",
    "        clf_nn = MLPClassifier(\n",
    "                hidden_layer_sizes=tup,\n",
    "                max_iter=2000,\n",
    "                early_stopping=True,\n",
    "                shuffle=True,\n",
    "                alpha=alpha,\n",
    "                learning_rate='adaptive'\n",
    "            )\n",
    "\n",
    "        clf_nn.fit(xtrain, ytrain)\n",
    "        ypred = clf_nn.predict(xtest)\n",
    "        errs_acc.append(accuracy_score(ytest,ypred))\n",
    "        errs_f1.append(f1_score(ytest,ypred,average='weighted'))\n",
    "        rec_ban.append(np.sum(np.logical_and(ytest=='banana',ypred=='banana'))/np.sum(ytest=='banana'))\n",
    "        loss.append(clf_nn.loss_)\n",
    "\n",
    "    errs_acc = np.array(errs_acc)\n",
    "    errs_f1 = np.array(errs_f1)\n",
    "    rec_ban = np.array(rec_ban)\n",
    "    loss = np.array(loss)\n",
    "    print('Train loss:',np.mean(loss),'+-',np.std(loss))\n",
    "    print('Accuracy:',np.mean(errs_acc),'+-',np.std(errs_acc))\n",
    "    print('F1-score:',np.mean(errs_f1),'+-',np.std(errs_f1))\n",
    "    print('Recall bananas:',np.mean(rec_ban),'+-',np.std(rec_ban))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>Temp.</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>class</th>\n",
       "      <th>t0</th>\n",
       "      <th>dt</th>\n",
       "      <th>t0_delay</th>\n",
       "      <th>dt_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.490250</td>\n",
       "      <td>12.8621</td>\n",
       "      <td>10.3683</td>\n",
       "      <td>10.4383</td>\n",
       "      <td>11.6699</td>\n",
       "      <td>13.4931</td>\n",
       "      <td>13.3423</td>\n",
       "      <td>8.04169</td>\n",
       "      <td>8.73901</td>\n",
       "      <td>26.2257</td>\n",
       "      <td>59.0528</td>\n",
       "      <td>0</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>background</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.490528</td>\n",
       "      <td>12.8617</td>\n",
       "      <td>10.3682</td>\n",
       "      <td>10.4375</td>\n",
       "      <td>11.6697</td>\n",
       "      <td>13.4927</td>\n",
       "      <td>13.3412</td>\n",
       "      <td>8.04133</td>\n",
       "      <td>8.73908</td>\n",
       "      <td>26.2308</td>\n",
       "      <td>59.0299</td>\n",
       "      <td>0</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>background</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.490806</td>\n",
       "      <td>12.8607</td>\n",
       "      <td>10.3686</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>11.6696</td>\n",
       "      <td>13.4924</td>\n",
       "      <td>13.3405</td>\n",
       "      <td>8.04101</td>\n",
       "      <td>8.73915</td>\n",
       "      <td>26.2365</td>\n",
       "      <td>59.0093</td>\n",
       "      <td>0</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>background</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.491084</td>\n",
       "      <td>12.8602</td>\n",
       "      <td>10.3686</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>11.6697</td>\n",
       "      <td>13.4921</td>\n",
       "      <td>13.3398</td>\n",
       "      <td>8.04086</td>\n",
       "      <td>8.73936</td>\n",
       "      <td>26.2416</td>\n",
       "      <td>58.9905</td>\n",
       "      <td>0</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>background</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.491373</td>\n",
       "      <td>12.8595</td>\n",
       "      <td>10.3688</td>\n",
       "      <td>10.4374</td>\n",
       "      <td>11.6699</td>\n",
       "      <td>13.4919</td>\n",
       "      <td>13.3390</td>\n",
       "      <td>8.04087</td>\n",
       "      <td>8.73986</td>\n",
       "      <td>26.2462</td>\n",
       "      <td>58.9736</td>\n",
       "      <td>0</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>background</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time       R1       R2       R3       R4       R5       R6       R7  \\\n",
       "0  12.490250  12.8621  10.3683  10.4383  11.6699  13.4931  13.3423  8.04169   \n",
       "1  12.490528  12.8617  10.3682  10.4375  11.6697  13.4927  13.3412  8.04133   \n",
       "2  12.490806  12.8607  10.3686  10.4370  11.6696  13.4924  13.3405  8.04101   \n",
       "3  12.491084  12.8602  10.3686  10.4370  11.6697  13.4921  13.3398  8.04086   \n",
       "4  12.491373  12.8595  10.3688  10.4374  11.6699  13.4919  13.3390  8.04087   \n",
       "\n",
       "        R8    Temp.  Humidity  id      date       class     t0    dt  \\\n",
       "0  8.73901  26.2257   59.0528   0  07-04-15  background  13.49  1.64   \n",
       "1  8.73908  26.2308   59.0299   0  07-04-15  background  13.49  1.64   \n",
       "2  8.73915  26.2365   59.0093   0  07-04-15  background  13.49  1.64   \n",
       "3  8.73936  26.2416   58.9905   0  07-04-15  background  13.49  1.64   \n",
       "4  8.73986  26.2462   58.9736   0  07-04-15  background  13.49  1.64   \n",
       "\n",
       "   t0_delay  dt_delay  \n",
       "0       0.0       0.0  \n",
       "1       0.0       0.0  \n",
       "2       0.0       0.0  \n",
       "3       0.0       0.0  \n",
       "4       0.0       0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity']\n",
    "\n",
    "df_db = group_datafiles_byID('../datasets/preprocessed/HT_Sensor_prep_metadata.dat', '../datasets/preprocessed/HT_Sensor_prep_dataset.dat')\n",
    "df_db = reclassify_series_samples(df_db)\n",
    "df_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>\n",
      "Alpha: 0.1\n",
      "##############################################\n",
      "\t Hidden layers: 1\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.36439495614577544 +- 0.02154308323919161\n",
      "Accuracy: 0.8414925093983957 +- 0.03205808447781048\n",
      "F1-score: 0.8248495700474063 +- 0.040662127331983974\n",
      "Recall bananas: 0.20894162557954427 +- 0.10269828337888062\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.29394989438794517 +- 0.02299163910422099\n",
      "Accuracy: 0.8420864215354106 +- 0.050105374962669945\n",
      "F1-score: 0.8215395564119155 +- 0.0595370460638927\n",
      "Recall bananas: 0.20786677266283388 +- 0.09736478307023012\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 16\n",
      "Train loss: 0.22796668428559053 +- 0.021724370601683172\n",
      "Accuracy: 0.7926713150481643 +- 0.04742558095032711\n",
      "F1-score: 0.7785714316435802 +- 0.05049925052450031\n",
      "Recall bananas: 0.2145449389813968 +- 0.09986174503858439\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 2\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.3053438411410784 +- 0.010913760999942861\n",
      "Accuracy: 0.8399865660064124 +- 0.04296194447002654\n",
      "F1-score: 0.8246748236947743 +- 0.050505592430421374\n",
      "Recall bananas: 0.26629727975706236 +- 0.06227086029546932\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.22075950388327356 +- 0.008098743617695112\n",
      "Accuracy: 0.8033123833809019 +- 0.0068466394188207436\n",
      "F1-score: 0.7969678929085686 +- 0.012145557914559374\n",
      "Recall bananas: 0.22059520646034594 +- 0.05771573541618891\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 16\n",
      "Train loss: 0.13677103552463765 +- 0.0062459675318604635\n",
      "Accuracy: 0.7654820455379545 +- 0.041546382024711094\n",
      "F1-score: 0.7697319207507654 +- 0.028763957057385867\n",
      "Recall bananas: 0.19550207928267804 +- 0.041724517009449354\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 3\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.29445895858291465 +- 0.023685837093807092\n",
      "Accuracy: 0.807892157334374 +- 0.0584108678483586\n",
      "F1-score: 0.8003476733618736 +- 0.062113858431870596\n",
      "Recall bananas: 0.31235548732377894 +- 0.14321485008078866\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.17290138108867042 +- 0.016271535893787898\n",
      "Accuracy: 0.8121499080578356 +- 0.03007854305692165\n",
      "F1-score: 0.7964337596425243 +- 0.03828817675162847\n",
      "Recall bananas: 0.1928302229314381 +- 0.05855764034301878\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 16\n",
      "Train loss: 0.10891169452839437 +- 0.008128767241602643\n",
      "Accuracy: 0.77788345414905 +- 0.02421841725519316\n",
      "F1-score: 0.7810205063846273 +- 0.030323627631072277\n",
      "Recall bananas: 0.27783876982040867 +- 0.08466389306145095\n",
      "==============================================\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>\n",
      "Alpha: 0.01\n",
      "##############################################\n",
      "\t Hidden layers: 1\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.3249858290258955 +- 0.037288906080046196\n",
      "Accuracy: 0.825316642354023 +- 0.03312743116765442\n",
      "F1-score: 0.8063700464686085 +- 0.03653524220894713\n",
      "Recall bananas: 0.22699925411069888 +- 0.08325721289190358\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.24548451424031414 +- 0.03377619049747889\n",
      "Accuracy: 0.8094896427152705 +- 0.03329766797555669\n",
      "F1-score: 0.8014212237023793 +- 0.03932526000088114\n",
      "Recall bananas: 0.2728640611931257 +- 0.03719976875314856\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 16\n",
      "Train loss: 0.15675597475319045 +- 0.010401130359995564\n",
      "Accuracy: 0.7932117368962657 +- 0.03860736197911965\n",
      "F1-score: 0.7810126114525684 +- 0.04062144145359601\n",
      "Recall bananas: 0.28345033746556664 +- 0.08966599782095855\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 2\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.2887314517076115 +- 0.016950890432273276\n",
      "Accuracy: 0.8141533349260619 +- 0.048651075112200445\n",
      "F1-score: 0.798026009249779 +- 0.0429129820308923\n",
      "Recall bananas: 0.22704119024083486 +- 0.09690349697894211\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.17824062354346967 +- 0.015867976581245957\n",
      "Accuracy: 0.8020316268662814 +- 0.03846891782600018\n",
      "F1-score: 0.804268383865882 +- 0.03325764453231974\n",
      "Recall bananas: 0.30487669550702384 +- 0.079787628741086\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 16\n",
      "Train loss: 0.06787310338464767 +- 0.008228992834531077\n",
      "Accuracy: 0.7376172636174063 +- 0.03944052625946917\n",
      "F1-score: 0.7416370705859707 +- 0.037813672270951566\n",
      "Recall bananas: 0.18347893493751222 +- 0.05077696312183622\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 3\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.3023592103141989 +- 0.037496632673599865\n",
      "Accuracy: 0.8468748907315234 +- 0.047730525925605304\n",
      "F1-score: 0.834948008140158 +- 0.0546955158848145\n",
      "Recall bananas: 0.2733877485052332 +- 0.17216307987212828\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.14109352390701596 +- 0.012978300809774605\n",
      "Accuracy: 0.7704364289277781 +- 0.0536134299770563\n",
      "F1-score: 0.7746340164350892 +- 0.05240261728451704\n",
      "Recall bananas: 0.2442743492455623 +- 0.09203416385846999\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 16\n",
      "Train loss: 0.05006350815946993 +- 0.006247526290937311\n",
      "Accuracy: 0.770316929372553 +- 0.02308299852431851\n",
      "F1-score: 0.7683298244321979 +- 0.026419729277503537\n",
      "Recall bananas: 0.2440069916002539 +- 0.062021426373556336\n",
      "==============================================\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>\n",
      "Alpha: 0.001\n",
      "##############################################\n",
      "\t Hidden layers: 1\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.3242994070636222 +- 0.01767406576631333\n",
      "Accuracy: 0.8543854089643379 +- 0.025194233994337747\n",
      "F1-score: 0.8312086623995784 +- 0.0406255681504029\n",
      "Recall bananas: 0.244349281224225 +- 0.1356135747275864\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.24349780762747794 +- 0.0180377658208209\n",
      "Accuracy: 0.8398700850320022 +- 0.02698313409734083\n",
      "F1-score: 0.8231343030162173 +- 0.03214404811036593\n",
      "Recall bananas: 0.24308649514344438 +- 0.06610522923458292\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 16\n",
      "Train loss: 0.1498371549774096 +- 0.018820477788760313\n",
      "Accuracy: 0.7934001871841102 +- 0.03340282139477718\n",
      "F1-score: 0.7859662713113246 +- 0.036673571732284964\n",
      "Recall bananas: 0.1734212337413477 +- 0.09115019537602237\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 2\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.2663942980953126 +- 0.03611568267609419\n",
      "Accuracy: 0.8184918821101146 +- 0.03602002738058254\n",
      "F1-score: 0.8008068444170817 +- 0.044110430341246856\n",
      "Recall bananas: 0.22971123099338636 +- 0.0983269984160473\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1669481749987911 +- 0.0115103516657133\n",
      "Accuracy: 0.7810960421718576 +- 0.015640244446935764\n",
      "F1-score: 0.7767980712383297 +- 0.013167999840908913\n",
      "Recall bananas: 0.2136602859010403 +- 0.10486630301074099\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 16\n",
      "Train loss: 0.06250807849206433 +- 0.012097463956786951\n",
      "Accuracy: 0.7562773702105744 +- 0.033389186034020385\n",
      "F1-score: 0.763713857861914 +- 0.02966348795820711\n",
      "Recall bananas: 0.2969017997507465 +- 0.11205908391079757\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 3\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.27363762460100227 +- 0.0207385507502707\n",
      "Accuracy: 0.8227726926585787 +- 0.04966026398541586\n",
      "F1-score: 0.8124863456187688 +- 0.05884403393734762\n",
      "Recall bananas: 0.334669057520933 +- 0.19765387789816402\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.1398741629690068 +- 0.017248251009375704\n",
      "Accuracy: 0.7916713387089158 +- 0.025552402033975928\n",
      "F1-score: 0.7894495940925385 +- 0.027894053815988983\n",
      "Recall bananas: 0.33623865105676676 +- 0.10228485090255093\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 16\n",
      "Train loss: 0.035713789951946844 +- 0.009732314419106922\n",
      "Accuracy: 0.7467260365846814 +- 0.03474911687624072\n",
      "F1-score: 0.7473495512917182 +- 0.0433221250303452\n",
      "Recall bananas: 0.20159950886426095 +- 0.06461179934788529\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "# Validación simple de 5 ejecuciones para decidir la constante de aprendizaje, el número de capas ocultas y\n",
    "# el número de neuronas\n",
    "for alpha in [0.1,0.01,0.001]:\n",
    "    print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>')\n",
    "    print('Alpha:',alpha)\n",
    "    for n_hid_layers in range(1,4):\n",
    "        print('##############################################')\n",
    "        print('\\t Hidden layers:',n_hid_layers)\n",
    "        for n_neur in [4,8,16]:\n",
    "            print('==============================================')\n",
    "            print('\\t \\t Neurons per layer:',n_neur)\n",
    "            hyper_sim(df_db,5,n_hid_layers,n_neur,alpha,features)\n",
    "            print('==============================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos 3 capas ocultas, 4 neuronas por capa y un alpha 0.01\n",
    "\n",
    "Ahora probamos a hacer bagging con 20 estimadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7741905663284396\n",
      "\tReal banana percentage: 0.11463473686527414\n",
      "\tReal wine percentage: 0.11117469680628618\n",
      "------------------------------------------\n",
      "Accuracy: 0.8511610503378602\n",
      "Recall on background: 0.9603341123222399\n",
      "Recall on banana: 0.21235743635037058\n",
      "Recall on wine: 0.7495941397743021\n",
      "F1-score: 0.828924712641002\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7683214404684678\n",
      "\tReal banana percentage: 0.10617230920279819\n",
      "\tReal wine percentage: 0.12550625032873397\n",
      "------------------------------------------\n",
      "Accuracy: 0.8505049353928152\n",
      "Recall on background: 0.949272923310381\n",
      "Recall on banana: 0.1778062172315568\n",
      "Recall on wine: 0.8149402807850806\n",
      "F1-score: 0.8289392454642864\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7268808410219711\n",
      "\tReal banana percentage: 0.0831863759892998\n",
      "\tReal wine percentage: 0.189932782988729\n",
      "------------------------------------------\n",
      "Accuracy: 0.8643690205399511\n",
      "Recall on background: 0.974191884859708\n",
      "Recall on banana: 0.2058989195555328\n",
      "Recall on wine: 0.7324676489717195\n",
      "F1-score: 0.8492760478619102\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.794991974317817\n",
      "\tReal banana percentage: 0.06999250936329587\n",
      "\tReal wine percentage: 0.1350155163188871\n",
      "------------------------------------------\n",
      "Accuracy: 0.8813782771535581\n",
      "Recall on background: 0.947525978571044\n",
      "Recall on banana: 0.2183219178082192\n",
      "Recall on wine: 0.8356212154836256\n",
      "F1-score: 0.8697563960118418\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7530087028954698\n",
      "\tReal banana percentage: 0.08673827972476984\n",
      "\tReal wine percentage: 0.16025301737976033\n",
      "------------------------------------------\n",
      "Accuracy: 0.8699424723858775\n",
      "Recall on background: 0.9744939994353765\n",
      "Recall on banana: 0.2110738758565498\n",
      "Recall on wine: 0.7352861551789485\n",
      "F1-score: 0.8571532016465677\n",
      "==============================================\n",
      "Accuracy: 0.8634711511620126 +- 0.011687691497926778\n",
      "F1-score: 0.8468099207251216 +- 0.01599279633991069\n",
      "Recall bananas: 0.20509167336044584 +- 0.014203979648387289\n"
     ]
    }
   ],
   "source": [
    "errs_acc = []\n",
    "errs_f1 = []\n",
    "rec_ban = []\n",
    "for i in range(5):\n",
    "    df_train, df_test = split_series_byID(0.75, df_db)\n",
    "    df_train, df_test = norm_train_test(df_train,df_test,features_to_norm=features)\n",
    "    xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "    xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "\n",
    "    clf_nn = MLPClassifier(\n",
    "        hidden_layer_sizes=(4,4,4),\n",
    "        max_iter=2000,\n",
    "        early_stopping=True,\n",
    "        shuffle=True,\n",
    "        alpha=0.01,\n",
    "        learning_rate='adaptive'\n",
    "        )\n",
    "\n",
    "    bag = BaggingClassifier(base_estimator=clf_nn,n_estimators=20,n_jobs=3)\n",
    "\n",
    "    bag.fit(xtrain, ytrain)\n",
    "    ypred = bag.predict(xtest)\n",
    "    metric_report(ytest, ypred)\n",
    "    errs_acc.append(accuracy_score(ytest,ypred))\n",
    "    errs_f1.append(f1_score(ytest,ypred,average='weighted'))\n",
    "    rec_ban.append(np.sum(np.logical_and(ytest=='banana',ypred=='banana'))/np.sum(ytest=='banana'))\n",
    "\n",
    "errs_acc = np.array(errs_acc)\n",
    "errs_f1 = np.array(errs_f1)\n",
    "rec_ban = np.array(rec_ban)\n",
    "print('Accuracy:',np.mean(errs_acc),'+-',np.std(errs_acc))\n",
    "print('F1-score:',np.mean(errs_f1),'+-',np.std(errs_f1))\n",
    "print('Recall bananas:',np.mean(rec_ban),'+-',np.std(rec_ban))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity',\n",
    "            'R1_mean', 'R2_mean', 'R3_mean', 'R4_mean', 'R5_mean', 'R6_mean', 'R7_mean',\n",
    "            'R8_mean', 'Temp._mean', 'Humidity_mean', 'R1_std', 'R2_std', 'R3_std', 'R4_std',\n",
    "            'R5_std', 'R6_std', 'R7_std', 'R8_std', 'Temp._std', 'Humidity_std']\n",
    "\n",
    "win_df = pd.read_pickle('../datasets/preprocessed/window120_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>\n",
      "Alpha: 0.01\n",
      "##############################################\n",
      "\t Hidden layers: 2\n",
      "==============================================\n",
      "\t \t Neurons per layer: 2\n",
      "Train loss: 0.3369292638080534 +- 0.01898777366073932\n",
      "Accuracy: 0.8614995653739118 +- 0.013802793278683207\n",
      "F1-score: 0.8477053916986094 +- 0.02269791360032949\n",
      "Recall bananas: 0.27286655706901736 +- 0.13537520341231715\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.25103889475688124 +- 0.02103813588063515\n",
      "Accuracy: 0.8550185358754737 +- 0.01473824536252829\n",
      "F1-score: 0.8413171659320327 +- 0.011710756562335249\n",
      "Recall bananas: 0.32072884775245203 +- 0.14954677863898094\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.15008099671145567 +- 0.006708852855497587\n",
      "Accuracy: 0.8055775903424107 +- 0.021140383711052996\n",
      "F1-score: 0.8088981076874298 +- 0.022004382367473173\n",
      "Recall bananas: 0.33186436122857177 +- 0.06900749905851701\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 3\n",
      "==============================================\n",
      "\t \t Neurons per layer: 2\n",
      "Train loss: 0.36515380967254024 +- 0.016346841965983894\n",
      "Accuracy: 0.8457524692071055 +- 0.012476117291074068\n",
      "F1-score: 0.8063862970693828 +- 0.013472524314098748\n",
      "Recall bananas: 0.019731324273896508 +- 0.020653420335793513\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.24958287028989287 +- 0.010357203374409379\n",
      "Accuracy: 0.8493415431126652 +- 0.022649597963754882\n",
      "F1-score: 0.8423800188661901 +- 0.024299416864581567\n",
      "Recall bananas: 0.31809172475993536 +- 0.10814365897086098\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.11896837362206596 +- 0.016618847416068082\n",
      "Accuracy: 0.7918528243849842 +- 0.03691441689721588\n",
      "F1-score: 0.7961085512934247 +- 0.02929042060708762\n",
      "Recall bananas: 0.22091449767627283 +- 0.09641044433721749\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 4\n",
      "==============================================\n",
      "\t \t Neurons per layer: 2\n",
      "Train loss: 0.3664332717405763 +- 0.022783559147086425\n",
      "Accuracy: 0.8423385049415483 +- 0.010022318958488059\n",
      "F1-score: 0.8026024002440989 +- 0.016660137470812308\n",
      "Recall bananas: 0.024277453220965736 +- 0.04721509066188733\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.24979221884499525 +- 0.020955411411107752\n",
      "Accuracy: 0.8126161703065076 +- 0.047107488560587954\n",
      "F1-score: 0.7922195396666007 +- 0.06435632900053101\n",
      "Recall bananas: 0.2701052359720566 +- 0.16252694186429312\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.0959376008046629 +- 0.012484889292800144\n",
      "Accuracy: 0.7569341256665212 +- 0.04009881657066456\n",
      "F1-score: 0.7546829682244047 +- 0.04092144438779055\n",
      "Recall bananas: 0.27622250463218284 +- 0.08651104376160111\n",
      "==============================================\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>\n",
      "Alpha: 0.001\n",
      "##############################################\n",
      "\t Hidden layers: 2\n",
      "==============================================\n",
      "\t \t Neurons per layer: 2\n",
      "Train loss: 0.3742061012218585 +- 0.022410954794798158\n",
      "Accuracy: 0.846074021877174 +- 0.01138556271616876\n",
      "F1-score: 0.8113874951660185 +- 0.01234351932795926\n",
      "Recall bananas: 0.05522274798913555 +- 0.06524748044823148\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.2349243423399287 +- 0.014568099253493602\n",
      "Accuracy: 0.8532286689394427 +- 0.005300964867911445\n",
      "F1-score: 0.8366710811477457 +- 0.010323677380650544\n",
      "Recall bananas: 0.31410035331814673 +- 0.08272865920349463\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.1479956743252899 +- 0.02071038341667576\n",
      "Accuracy: 0.7975716365823718 +- 0.06024018092752024\n",
      "F1-score: 0.8038885444256495 +- 0.05471022858909473\n",
      "Recall bananas: 0.3609078012684262 +- 0.11131226273949112\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 3\n",
      "==============================================\n",
      "\t \t Neurons per layer: 2\n",
      "Train loss: 0.361208535526618 +- 0.03307333595896729\n",
      "Accuracy: 0.8317456617420745 +- 0.03668843412029129\n",
      "F1-score: 0.7812252607794095 +- 0.04332961019937066\n",
      "Recall bananas: 0.01027486317317287 +- 0.02054972634634574\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.23124858628228795 +- 0.024645356046942724\n",
      "Accuracy: 0.8417800272238362 +- 0.03172060611606521\n",
      "F1-score: 0.8342446096786507 +- 0.03302611932907668\n",
      "Recall bananas: 0.3263580422265571 +- 0.11254692526731452\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.10352512625868218 +- 0.006693226605781877\n",
      "Accuracy: 0.8030593843742123 +- 0.03575260263729497\n",
      "F1-score: 0.8014615768380796 +- 0.03533195167672996\n",
      "Recall bananas: 0.3135065533358257 +- 0.053522667876942355\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 4\n",
      "==============================================\n",
      "\t \t Neurons per layer: 2\n",
      "Train loss: 0.4228506189525755 +- 0.1550080041991051\n",
      "Accuracy: 0.8110340281659696 +- 0.009945822216335564\n",
      "F1-score: 0.7458344512342154 +- 0.02159543013556887\n",
      "Recall bananas: 0.0 +- 0.0\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.2616773730648665 +- 0.033848763155626134\n",
      "Accuracy: 0.8466368610177458 +- 0.025959396176523958\n",
      "F1-score: 0.8351268328737564 +- 0.030083723267942414\n",
      "Recall bananas: 0.28536870628229005 +- 0.12782930844562104\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.11256229154783981 +- 0.021236493589919865\n",
      "Accuracy: 0.8064533172480723 +- 0.03204500602290605\n",
      "F1-score: 0.8087032209303258 +- 0.030956274807634736\n",
      "Recall bananas: 0.33893008018518844 +- 0.08314821504529067\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "# Validación simple de 5 ejecuciones para decidir la constante de aprendizaje, el número de capas ocultas y\n",
    "# el número de neuronas\n",
    "for alpha in [0.01,0.001]:\n",
    "    print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>')\n",
    "    print('Alpha:',alpha)\n",
    "    for n_hid_layers in range(2,5):\n",
    "        print('##############################################')\n",
    "        print('\\t Hidden layers:',n_hid_layers)\n",
    "        for n_neur in [2,4,8]:\n",
    "            print('==============================================')\n",
    "            print('\\t \\t Neurons per layer:',n_neur)\n",
    "            hyper_sim(win_df,5,n_hid_layers,n_neur,alpha,features)\n",
    "            print('==============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.24018066820164438 +- 0.023418848195325886\n",
      "Accuracy: 0.8637574268900602 +- 0.02871614724926834\n",
      "F1-score: 0.8553617572371873 +- 0.031009063536019333\n",
      "Recall bananas: 0.39207973741325436 +- 0.092974568441552\n"
     ]
    }
   ],
   "source": [
    "hyper_sim(win_df,10,3,4,0.01,features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que antes, elegimos 3 capas ocultas, 4 neuronas por capa y un alpha 0.01. Aunque hay mejores resultados, tienen demasiada desviación típica como para ser fiables.\n",
    "\n",
    "Ahora probamos a hacer bagging con 20 estimadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7869345926926833\n",
      "\tReal banana percentage: 0.09259234484327131\n",
      "\tReal wine percentage: 0.12047306246404538\n",
      "------------------------------------------\n",
      "Accuracy: 0.895500822775496\n",
      "Recall on background: 0.9620033661447442\n",
      "Recall on banana: 0.6426335307999808\n",
      "Recall on wine: 0.65545067555062\n",
      "F1-score: 0.8939343748402855\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7070396595801938\n",
      "\tReal banana percentage: 0.09927509418729817\n",
      "\tReal wine percentage: 0.19368524623250807\n",
      "------------------------------------------\n",
      "Accuracy: 0.818205900161464\n",
      "Recall on background: 0.9609517635934368\n",
      "Recall on banana: 0.16950444726810673\n",
      "Recall on wine: 0.6296159607494084\n",
      "F1-score: 0.792719333808237\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7244155558003745\n",
      "\tReal banana percentage: 0.12466674011237193\n",
      "\tReal wine percentage: 0.1509177040872535\n",
      "------------------------------------------\n",
      "Accuracy: 0.8511093973779883\n",
      "Recall on background: 0.9761904761904762\n",
      "Recall on banana: 0.22364793213149523\n",
      "Recall on wine: 0.7690308640172862\n",
      "F1-score: 0.8267536395100213\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7265061897601718\n",
      "\tReal banana percentage: 0.14813730577991865\n",
      "\tReal wine percentage: 0.12535650445990962\n",
      "------------------------------------------\n",
      "Accuracy: 0.8110603983978922\n",
      "Recall on background: 0.9787475655247783\n",
      "Recall on banana: 0.3250194622432481\n",
      "Recall on wine: 0.4135942254617508\n",
      "F1-score: 0.7826629441443967\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7897403615041249\n",
      "\tReal banana percentage: 0.11884029899366971\n",
      "\tReal wine percentage: 0.09141933950220547\n",
      "------------------------------------------\n",
      "Accuracy: 0.8333480071490831\n",
      "Recall on background: 0.9313987257454055\n",
      "Recall on banana: 0.2687435175581568\n",
      "Recall on wine: 0.7202773631241874\n",
      "F1-score: 0.8190224582467523\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7516224137329472\n",
      "\tReal banana percentage: 0.13967586615958968\n",
      "\tReal wine percentage: 0.10870172010746311\n",
      "------------------------------------------\n",
      "Accuracy: 0.8572406754823628\n",
      "Recall on background: 0.974712483607794\n",
      "Recall on banana: 0.2841441328920252\n",
      "Recall on wine: 0.7813753811587225\n",
      "F1-score: 0.8342695993194671\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.775005304650138\n",
      "\tReal banana percentage: 0.09287626291478283\n",
      "\tReal wine percentage: 0.13211843243507923\n",
      "------------------------------------------\n",
      "Accuracy: 0.8733902427081464\n",
      "Recall on background: 0.9733321399049119\n",
      "Recall on banana: 0.27428496111770134\n",
      "Recall on wine: 0.708289579343999\n",
      "F1-score: 0.8589833048845553\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7837274799946354\n",
      "\tReal banana percentage: 0.12850373284456168\n",
      "\tReal wine percentage: 0.0877687871608029\n",
      "------------------------------------------\n",
      "Accuracy: 0.8782422102016183\n",
      "Recall on background: 0.9694715706854066\n",
      "Recall on banana: 0.4161071490694034\n",
      "Recall on wine: 0.7402332807008608\n",
      "F1-score: 0.8660715107969879\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7478306254163714\n",
      "\tReal banana percentage: 0.08651614354152257\n",
      "\tReal wine percentage: 0.16565323104210603\n",
      "------------------------------------------\n",
      "Accuracy: 0.884688989124485\n",
      "Recall on background: 0.971169831876032\n",
      "Recall on banana: 0.3042817205355829\n",
      "Recall on wine: 0.7974077204846436\n",
      "F1-score: 0.8727213513492469\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.6950241950303203\n",
      "\tReal banana percentage: 0.07461053147395716\n",
      "\tReal wine percentage: 0.23036527349572247\n",
      "------------------------------------------\n",
      "Accuracy: 0.8707352430732793\n",
      "Recall on background: 0.9521918202595755\n",
      "Recall on banana: 0.5464944447485086\n",
      "Recall on wine: 0.7299913140588162\n",
      "F1-score: 0.8697969321207526\n",
      "==============================================\n",
      "Accuracy: 0.8573521886451816 +- 0.02714016327267132\n",
      "F1-score: 0.8416935449020702 +- 0.03471344058068982\n",
      "Recall bananas: 0.3454861298364209 +- 0.14012170114717798\n"
     ]
    }
   ],
   "source": [
    "errs_acc = []\n",
    "errs_f1 = []\n",
    "rec_ban = []\n",
    "for i in range(10):\n",
    "    df_train, df_test = split_series_byID(0.75, win_df)\n",
    "    df_train, df_test = norm_train_test(df_train,df_test,features_to_norm=features)\n",
    "    xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "    xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "\n",
    "    clf_nn = MLPClassifier(\n",
    "        hidden_layer_sizes=(4,4,4),\n",
    "        max_iter=2000,\n",
    "        early_stopping=True,\n",
    "        shuffle=True,\n",
    "        alpha=0.01,\n",
    "        learning_rate='adaptive'\n",
    "        )\n",
    "\n",
    "    bag = BaggingClassifier(base_estimator=clf_nn,n_estimators=20,n_jobs=3)\n",
    "\n",
    "    bag.fit(xtrain, ytrain)\n",
    "    ypred = bag.predict(xtest)\n",
    "    metric_report(ytest, ypred)\n",
    "    errs_acc.append(accuracy_score(ytest,ypred))\n",
    "    errs_f1.append(f1_score(ytest,ypred,average='weighted'))\n",
    "    rec_ban.append(np.sum(np.logical_and(ytest=='banana',ypred=='banana'))/np.sum(ytest=='banana'))\n",
    "\n",
    "errs_acc = np.array(errs_acc)\n",
    "errs_f1 = np.array(errs_f1)\n",
    "rec_ban = np.array(rec_ban)\n",
    "print('Accuracy:',np.mean(errs_acc),'+-',np.std(errs_acc))\n",
    "print('F1-score:',np.mean(errs_f1),'+-',np.std(errs_f1))\n",
    "print('Recall bananas:',np.mean(rec_ban),'+-',np.std(rec_ban))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'Temp.', 'Humidity',\n",
    "            'R1_mean', 'R2_mean', 'R3_mean', 'R4_mean', 'R5_mean', 'R6_mean', 'R7_mean',\n",
    "            'R8_mean', 'Temp._mean', 'Humidity_mean', 'R1_std', 'R2_std', 'R3_std', 'R4_std',\n",
    "            'R5_std', 'R6_std', 'R7_std', 'R8_std', 'Temp._std', 'Humidity_std']\n",
    "\n",
    "win_df = pd.read_pickle('../datasets/preprocessed/window120_dataset.pkl')\n",
    "\n",
    "over_dict = {'banana': 175000, 'wine': 175000}\n",
    "under_dict = {'background': 500000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>\n",
      "Alpha: 0.01\n",
      "##############################################\n",
      "\t Hidden layers: 2\n",
      "==============================================\n",
      "\t \t Neurons per layer: 2\n",
      "Train loss: 0.5488535924240698 +- 0.21046260621523777\n",
      "Accuracy: 0.8271824672424748 +- 0.0444991777822927\n",
      "F1-score: 0.8038085542601353 +- 0.07510036911176725\n",
      "Recall bananas: 0.3496213514627672 +- 0.2131246020306895\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.3185648758281586 +- 0.022205933514169364\n",
      "Accuracy: 0.8121943421500776 +- 0.029241303750929024\n",
      "F1-score: 0.819819580056623 +- 0.02658073479470294\n",
      "Recall bananas: 0.4106811750623657 +- 0.09157163857353492\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.1440066255811115 +- 0.016734622110107483\n",
      "Accuracy: 0.7561186546743115 +- 0.01949760318613811\n",
      "F1-score: 0.7584008535355601 +- 0.006767609476800042\n",
      "Recall bananas: 0.34648036125721304 +- 0.13061643798541048\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 3\n",
      "==============================================\n",
      "\t \t Neurons per layer: 2\n",
      "Train loss: 0.4749120460553636 +- 0.07229212674257438\n",
      "Accuracy: 0.8058973559177008 +- 0.042117898121959325\n",
      "F1-score: 0.8111650950261126 +- 0.033304408664666385\n",
      "Recall bananas: 0.3944183011078244 +- 0.15314320962931444\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.3165684099893866 +- 0.021542345613225593\n",
      "Accuracy: 0.8428451569318092 +- 0.03978496260944134\n",
      "F1-score: 0.8480038725057085 +- 0.041129573916647545\n",
      "Recall bananas: 0.4801205899414942 +- 0.13934455665541717\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.14068777989182865 +- 0.014771036775252372\n",
      "Accuracy: 0.8138710322472636 +- 0.02881037124596384\n",
      "F1-score: 0.8165798344464525 +- 0.024792405398527517\n",
      "Recall bananas: 0.3973262302486393 +- 0.10131175094477714\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 4\n",
      "==============================================\n",
      "\t \t Neurons per layer: 2\n",
      "Train loss: 0.6628668743857279 +- 0.24542842623838187\n",
      "Accuracy: 0.7785795955406424 +- 0.02145364691733178\n",
      "F1-score: 0.7375322067382639 +- 0.0742547477581383\n",
      "Recall bananas: 0.2195408149499202 +- 0.19054269531295298\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.31409760763130784 +- 0.0182798391733188\n",
      "Accuracy: 0.820221715026093 +- 0.022278651136703808\n",
      "F1-score: 0.8280890888471752 +- 0.01691472958161564\n",
      "Recall bananas: 0.5005748040453433 +- 0.05278178504888124\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.13074412384164172 +- 0.02406207491901235\n",
      "Accuracy: 0.7725648214048804 +- 0.06319717325240255\n",
      "F1-score: 0.7841021629282848 +- 0.0505155984908297\n",
      "Recall bananas: 0.3872129287190809 +- 0.03898341646986164\n",
      "==============================================\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>\n",
      "Alpha: 0.001\n",
      "##############################################\n",
      "\t Hidden layers: 2\n",
      "==============================================\n",
      "\t \t Neurons per layer: 2\n",
      "Train loss: 0.4706504229832543 +- 0.07628944396298978\n",
      "Accuracy: 0.8024340798696732 +- 0.02764076220404015\n",
      "F1-score: 0.8036437213863845 +- 0.020123680438554874\n",
      "Recall bananas: 0.38900154848264 +- 0.13078109968466003\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.30904169541283627 +- 0.03011708986544716\n",
      "Accuracy: 0.8213143710852014 +- 0.033338247418183704\n",
      "F1-score: 0.8218123622105894 +- 0.03486508973741975\n",
      "Recall bananas: 0.3789550950182215 +- 0.19201985259565182\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.16323434471033701 +- 0.007720187068142708\n",
      "Accuracy: 0.7909652070345307 +- 0.031148654346289367\n",
      "F1-score: 0.8067449660662044 +- 0.02839717735725225\n",
      "Recall bananas: 0.36763450551050714 +- 0.09550977730843109\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 3\n",
      "==============================================\n",
      "\t \t Neurons per layer: 2\n",
      "Train loss: 0.5702018389037453 +- 0.20521993045581097\n",
      "Accuracy: 0.8374427953609104 +- 0.029882243785188636\n",
      "F1-score: 0.823198812598469 +- 0.06858880149578664\n",
      "Recall bananas: 0.3145235866841651 +- 0.1915083580084091\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.30584589543525975 +- 0.012607840004424357\n",
      "Accuracy: 0.8299092914144393 +- 0.014828232796108443\n",
      "F1-score: 0.8341902470517774 +- 0.02075865577251638\n",
      "Recall bananas: 0.4506485263116282 +- 0.09425360869714228\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.1301210471554955 +- 0.010990508255847289\n",
      "Accuracy: 0.8129652177302313 +- 0.042711534631796846\n",
      "F1-score: 0.8196665763060407 +- 0.035264674312832374\n",
      "Recall bananas: 0.2886861105363917 +- 0.11811932042935577\n",
      "==============================================\n",
      "##############################################\n",
      "\t Hidden layers: 4\n",
      "==============================================\n",
      "\t \t Neurons per layer: 2\n",
      "Train loss: 0.5688919877552683 +- 0.19884132398553353\n",
      "Accuracy: 0.7887594172062785 +- 0.0318866452426906\n",
      "F1-score: 0.780089000216545 +- 0.07295742001038283\n",
      "Recall bananas: 0.36327148271510384 +- 0.2335671561557448\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 4\n",
      "Train loss: 0.31654335641498543 +- 0.003975020278552049\n",
      "Accuracy: 0.8327135029906385 +- 0.06109386497276588\n",
      "F1-score: 0.8413483785723648 +- 0.05099330491177666\n",
      "Recall bananas: 0.37148515400340976 +- 0.16940762028206108\n",
      "==============================================\n",
      "==============================================\n",
      "\t \t Neurons per layer: 8\n",
      "Train loss: 0.10584703540755183 +- 0.021617549521155112\n",
      "Accuracy: 0.7638128797803947 +- 0.012287494751308324\n",
      "F1-score: 0.7729602289369806 +- 0.023024132174864435\n",
      "Recall bananas: 0.3237496862921675 +- 0.13444905132438764\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "# Validación simple de 5 ejecuciones para decidir la constante de aprendizaje, el número de capas ocultas y\n",
    "# el número de neuronas\n",
    "for alpha in [0.01,0.001]:\n",
    "    print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>')\n",
    "    print('Alpha:',alpha)\n",
    "    for n_hid_layers in range(2,5):\n",
    "        print('##############################################')\n",
    "        print('\\t Hidden layers:',n_hid_layers)\n",
    "        for n_neur in [2,4,8]:\n",
    "            print('==============================================')\n",
    "            print('\\t \\t Neurons per layer:',n_neur)\n",
    "            hyper_sim(win_df,5,n_hid_layers,n_neur,alpha,features,over_dict=over_dict,under_dict=under_dict)\n",
    "            print('==============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2549249821288277 +- 0.02396171263553367\n",
      "Accuracy: 0.8450009759161426 +- 0.038346372438755875\n",
      "F1-score: 0.833654747589921 +- 0.04890055706443827\n",
      "Recall bananas: 0.338290871841337 +- 0.1905058852897362\n"
     ]
    }
   ],
   "source": [
    "hyper_sim(win_df,10,2,4,0.001,features,over_dict=over_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2503299377997425 +- 0.027380070003056072\n",
      "Accuracy: 0.8248288805993831 +- 0.02328144346620624\n",
      "F1-score: 0.8104826957935496 +- 0.028213516288456884\n",
      "Recall bananas: 0.3091208926005941 +- 0.13019222637709468\n"
     ]
    }
   ],
   "source": [
    "hyper_sim(win_df,10,3,4,0.01,features,over_dict=over_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3174721772856896 +- 0.027246001164953758\n",
      "Accuracy: 0.8224637333552776 +- 0.034269443248349775\n",
      "F1-score: 0.8301484949130975 +- 0.03307461316084157\n",
      "Recall bananas: 0.47073848708416133 +- 0.1181386744211724\n"
     ]
    }
   ],
   "source": [
    "# Mejor opción\n",
    "hyper_sim(win_df,10,3,4,0.01,features,over_dict=over_dict,under_dict=under_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7261303338023632\n",
      "\tReal banana percentage: 0.1202765016020479\n",
      "\tReal wine percentage: 0.15359316459558886\n",
      "------------------------------------------\n",
      "Accuracy: 0.8245588010917659\n",
      "Recall on background: 0.8768101138744754\n",
      "Recall on banana: 0.6473801050072236\n",
      "Recall on wine: 0.716280353200883\n",
      "F1-score: 0.8326610440983933\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7762145091408189\n",
      "\tReal banana percentage: 0.10652743536457862\n",
      "\tReal wine percentage: 0.11725805549460241\n",
      "------------------------------------------\n",
      "Accuracy: 0.873000916448311\n",
      "Recall on background: 0.9137284029998836\n",
      "Recall on banana: 0.4742921765822529\n",
      "Recall on wine: 0.9656184640223094\n",
      "F1-score: 0.8733368939127423\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7684564355994835\n",
      "\tReal banana percentage: 0.11653087574017186\n",
      "\tReal wine percentage: 0.1150126886603446\n",
      "------------------------------------------\n",
      "Accuracy: 0.862664173456213\n",
      "Recall on background: 0.9539231647190374\n",
      "Recall on banana: 0.29246580576144265\n",
      "Recall on wine: 0.8306429760384005\n",
      "F1-score: 0.8478286471763464\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7959305911906954\n",
      "\tReal banana percentage: 0.09101189890844724\n",
      "\tReal wine percentage: 0.11305750990085733\n",
      "------------------------------------------\n",
      "Accuracy: 0.9035437470386827\n",
      "Recall on background: 0.9326478120226436\n",
      "Recall on banana: 0.5593536663228722\n",
      "Recall on wine: 0.9757245087573637\n",
      "F1-score: 0.9033429718773707\n",
      "==============================================\n",
      "==============================================\n",
      "TEST SET PROPORTIONS:\n",
      "\tReal background percentage: 0.7956435195065966\n",
      "\tReal banana percentage: 0.06817399788317384\n",
      "\tReal wine percentage: 0.13618248261022958\n",
      "------------------------------------------\n",
      "Accuracy: 0.8481068343866649\n",
      "Recall on background: 0.8958400621883057\n",
      "Recall on banana: 0.4769358548428316\n",
      "Recall on wine: 0.7550374208405296\n",
      "F1-score: 0.8602011525013675\n",
      "==============================================\n",
      "Accuracy: 0.8623748944843275 +- 0.02623549086321932\n",
      "F1-score: 0.8634741419132439 +- 0.024048860438333274\n",
      "Recall bananas: 0.49008552170332464 +- 0.11748664384804525\n"
     ]
    }
   ],
   "source": [
    "errs_acc = []\n",
    "errs_f1 = []\n",
    "rec_ban = []\n",
    "for i in range(5):\n",
    "    df_train, df_test = split_series_byID(0.75, win_df)\n",
    "    df_train, df_test = norm_train_test(df_train,df_test,features_to_norm=features)\n",
    "    xtrain, ytrain = df_train[features].values, df_train['class'].values\n",
    "    over_sampling = SMOTE(sampling_strategy=over_dict)\n",
    "    under_sampling = RandomUnderSampler(sampling_strategy=under_dict)\n",
    "    xtrain, ytrain = over_sampling.fit_resample(xtrain, ytrain)\n",
    "    xtrain, ytrain = under_sampling.fit_resample(xtrain, ytrain)\n",
    "    xtest, ytest = df_test[features].values, df_test['class'].values\n",
    "\n",
    "    clf_nn = MLPClassifier(\n",
    "        hidden_layer_sizes=(4,4,4),\n",
    "        max_iter=2000,\n",
    "        early_stopping=True,\n",
    "        shuffle=True,\n",
    "        alpha=0.01,\n",
    "        learning_rate='adaptive'\n",
    "        )\n",
    "\n",
    "    bag = BaggingClassifier(base_estimator=clf_nn,n_estimators=20,n_jobs=3)\n",
    "\n",
    "    bag.fit(xtrain, ytrain)\n",
    "    ypred = bag.predict(xtest)\n",
    "    metric_report(ytest, ypred)\n",
    "    errs_acc.append(accuracy_score(ytest,ypred))\n",
    "    errs_f1.append(f1_score(ytest,ypred,average='weighted'))\n",
    "    rec_ban.append(np.sum(np.logical_and(ytest=='banana',ypred=='banana'))/np.sum(ytest=='banana'))\n",
    "\n",
    "errs_acc = np.array(errs_acc)\n",
    "errs_f1 = np.array(errs_f1)\n",
    "rec_ban = np.array(rec_ban)\n",
    "print('Accuracy:',np.mean(errs_acc),'+-',np.std(errs_acc))\n",
    "print('F1-score:',np.mean(errs_f1),'+-',np.std(errs_f1))\n",
    "print('Recall bananas:',np.mean(rec_ban),'+-',np.std(rec_ban))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
